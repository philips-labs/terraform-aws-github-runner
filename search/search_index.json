{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"GitHub Self-Hosted on AWS on Spot Instances","text":"<p>This Terraform module creates the required infrastructure needed to host GitHub Actions self-hosted, auto-scaling runners on AWS spot instances. It provides the required logic to handle the life cycle for scaling up and down using a set of AWS Lambda functions. Runners are scaled down to zero to avoid costs when no workflows are active.</p> <p> </p>"},{"location":"#motivation","title":"Motivation","text":"<p>GitHub Actions <code>self-hosted</code> runners provide a flexible option to run CI workloads on the infrastructure of your choice. However, currently GitHub does not provide tooling to automate the creation and scaling of action runners. This module creates the AWS infrastructure to host action runners on spot instances. It also provides lambda modules to orchestrate the life cycle of the action runners.</p> <p>Lambda was selected as the preferred runtime for two primary reasons. Firstly, it enables the development of compact components with limited access to AWS and GitHub. Secondly, it offers a scalable configuration with minimal expenses, applicable at both the repository and organizational levels. The Lambda functions will be responsible for provisioning Linux-based EC2 instances equipped with Docker to handle CI workloads compatible with Linux and/or Docker. The primary objective is to facilitate Docker-based workloads.</p> <p>A pertinent question may arise: why not opt for Kubernetes? The current strategy aligns closely with the implementation of GitHub's action runners. The chosen approach involves installing the runner on a host where the necessary software is readily available, maintaining proximity to GitHub's existing practices. Another viable option could be AWS Auto Scaling groups. However, this alternative usually demands broader permissions at the instance level from GitHub. Additionally, managing the scaling process, both up and down, becomes a non-trivial task in this scenario.</p>"},{"location":"#overview","title":"Overview","text":"<p>The module is designed to be used in a GitHub organization. It can also be used in a GitHub repository, but this does not supports all features. The module is receiving GitHub webhook events for the <code>workflow_job</code> event. The module will create a new runner if the event is for a workflow that requires a runner, and no runner is available. Alternatively the module can be configured as ephemeral runners. In this case the module will create a new runner for each workflow job event.</p> <p>For ephemeral runners a pool is can be configured. The pool maintains a minimum number of runners based on a schedule. The pool works only for org level runners.</p> <p>For non ephemeral runners with the idle config the module will avoid scaling down back to zero. Instead it will maintain a minimum number of runners based on a schedule. This avoids the need to scale up when a new workflow is triggered.</p>"},{"location":"#detailed-design","title":"Detailed design","text":"<p>The diagram below shows the architecture of the module, groups are indicating the different components. We will go through the components in the following sections.</p> <p> </p>"},{"location":"#webhook","title":"Webhook","text":"<p>The moment a GitHub action workflow requiring a <code>self-hosted</code> runner is triggered, GitHub will try to find a runner which can execute the workload. See additional notes for how the selection is made. The module can be deployed in two modes. One mode called <code>direct</code>, after accepting the <code>workflow_job</code> event event the module will dispatch the event to a SQS queue on which the scale-up function will act. The second mode, <code>eventbridge</code> will funnel events via the AWS EventBridge. the EventBridge enables act on other events then only the <code>workflow_job</code> event with status <code>queued</code>. besides that the EventBridge supports replay functionality. For future extensions to act on events or create a data lake we will relay on the EventBridge.</p> <p>For receiving the <code>workflow_job</code> event by the webhook (lambda), a webhook needs to be created in GitHub. The same app as for API calls can be used to create the webhook. Or a dedicated webhook can be defined.</p> <ul> <li>Create a GitHub app, define a webhook and subscribe the app to the <code>workflow_job</code> event.</li> <li>Create a webhook on enterprise, org or repo level, define a webhook and subscribe the app to the <code>workflow_job</code> event.</li> </ul> <p>In AWS an API gateway endpoint is created that is able to receive the GitHub webhook events via HTTP post. The gateway triggers the webhook lambda which will verify the signature of the event. This check guarantees the event is sent by the GitHub App. The lambda only handles <code>workflow_job</code> events with status <code>queued</code> and matching the runner labels. The accepted events are posted on a SQS queue. Messages on this queue will be delayed for a configurable amount of seconds (default 30 seconds) to give the available runners time to pick up this build.</p>"},{"location":"#control-plane","title":"Control plane","text":"<p>The \"Scale Up Runner\" Lambda actively monitors the SQS queue, processing incoming events. The Lambda conducts a series of checks to determine the necessity of creating a new EC2 spot instance. For instance, it refrains from creating an instance if a build is already initiated by an existing runner or if the maximum allowable number of runners has been reached.</p> <p>The Lambda first requests a JIT configuration or registration token from GitHub, which is needed later by the runner to register itself. This avoids the case that the EC2 instance, which later in the process will install the agent, needs administration permissions to register the runner. Next, the EC2 spot instance is created via the launch template. The launch template defines the specifications of the required instance and contains a <code>user_data</code> script. This script will install the required software and configure it. The configuration for the runner is shared via EC2 tags and the parameter store (SSM), from which the user data script will fetch it and delete it once it has been retrieved. Once the user data script is finished, the action runner should be online, and the workflow will start in seconds.</p> <p>The current method for scaling down runners employs a straightforward approach: at predefined intervals, the Lambda conducts a thorough examination of each runner (instance) to assess its activity. If a runner is found to be idle, it is deregistered from GitHub, and the associated AWS instance is terminated. For ephemeral runners the instance is terminated immediately after the workflow is finished. Instances not registered in GitHub as a runner after a minimal boot time will be marked orphan and removed in a next cycle. To avoid orphaned runners the scale down lambda is active in this case as well.</p>"},{"location":"#pool","title":"Pool","text":"<p>The pool is only designed for org level runners in ephemeral mode. The pool will maintain a minimum number of runners based on a schedule. Keeping a small pool can help to start jobs faster and avoid missed events are causing long hanging jobs. The pool is opt in, it will not be created by default.</p>"},{"location":"#agent-sync","title":"Agent sync","text":"<p>To address potential delays in downloading the GitHub Action Runner distribution, a lambda function has been implemented to synchronize the action runner binary from GitHub to an S3 bucket. This ensures that the EC2 instance can retrieve the distribution from the S3 bucket, mitigating the need to rely on internet downloads, which can occasionally take more than 10 minutes. The best way to speed up instance startup is to use a pre-built AMI with the runner binary already installed. See the examples for more details.</p>"},{"location":"#ssm-housekeeping","title":"SSM housekeeping","text":"<p>The control plane (scale up lambda) will store the runner registration configuration in the SSM parameter store. The token is stored in a secure string parameter. The token is deleted after the runner has registered itself. The token is also deleted after a configurable amount of time (default 24 hours). This house keeping ensures that your SSM parameter store does not fill up with old configuration.</p>"},{"location":"#ami-cleaner","title":"AMI cleaner","text":"<p>The AMI cleaner is a lambda that will clean up AMIs that are older than a configurable amount of days. This is useful when using the AMI builder to create AMIs. The cleaner will also check which AMIs are used the latest version of the launch template. And you can provide SSM config paths pointing to AMI IDs. The cleaner will not delete these AMIs. The AMI cleaner is opt in, it will not be created by default.</p>"},{"location":"#instance-termination-watcher","title":"Instance Termination Watcher","text":"<p>Warning</p> <p>This feature is Beta, changes will not trigger a major release as long in beta.</p> <p>The Instance Termination Watcher is creating log and optional metrics for termination of instances. Currently only spot termination warnings are watched. See configuration for more details.</p>"},{"location":"#job-retry","title":"Job Retry","text":"<p>Warning</p> <p>This feature is Beta, changes will not trigger a major release as long in beta.</p> <p>The Job Retry will allow you to retry scaling when a job is not started. When enabled the scale up lambda will send a retry message to the a SQS queue. The Job Retry lambda will check after a delay if the job is still queued, and if so, it will send a retry command to the scale up lambda via SQS. The feature is designed to be used with ephemeral runners. The feature is opt in, it will not be created by default.</p> <p>Consequences of enabling the feature are:</p> <ul> <li>Increase of calls to the GitHub API, could cause reaching the rate limit.</li> <li>Could create new instance when jobs are not started caused by other failures, resulting in more costs and useless instance creation.</li> </ul>"},{"location":"#security","title":"Security","text":"<p>Sensitive information such as secrets and private keys are stored securely in the SSM Parameter Store. These values undergo encryption using either the default KMS key for SSM or a custom KMS key, depending on the specified configuration.</p> <p>Permissions are managed in several places. Below are the most important ones. For details check the Terraform sources.</p> <ul> <li>The GitHub App requires access to actions and to publish <code>workflow_job</code> events to the AWS webhook (API gateway).</li> <li>The scale up lambda should have access to EC2 for creating and tagging instances.</li> <li>The scale down lambda should have access to EC2 to terminate instances.</li> </ul> <p>Besides these permissions, the lambdas also need permission to CloudWatch (for logging and scheduling), SSM and S3. For more details about the required permissions see the documentation of the IAM module which uses permission boundaries.</p>"},{"location":"#terraform-main-modules","title":"Terraform main modules","text":"<p>Currently we support two main modules. The <code>runners</code> module is the main module for creating runners. And the 'multi-runner' module is a wrapper around the <code>runners</code> module to create multiple runners in one go. The <code>multi-runner</code> module is useful for creating runners for multiple repositories or organizations.</p> <p>Both modules are built on top of the same base modules. When using the multi-runner module you can deploy different runners with only one deployment.</p> <p> </p>"},{"location":"#recommendations","title":"Recommendations","text":"<p>The module contains a lot of configuration options. The default values are a good starting point. But you may want to tweak some of the values. Below are some recommendations. We suggest the following configuration for the runners:</p> <ul> <li>Use the multi-runner module to create multiple runners in one go.</li> <li>Use the ephemeral runners for org level runners to improve the security of your runners.</li> <li>Use pre-built AMIs to speed up the startup of your runners.</li> </ul>"},{"location":"additional_notes/","title":"Runner Labels","text":"<p>Some CI systems require that all labels match between a job and a runner. In the case of GitHub Actions, workflows will be assigned to runners which have all the labels requested by the workflow, however it is not necessary the workflow mentions all labels.</p> <p>Labels specify the capabilities the runners have. The labels in the workflow are the capabilities needed. If the capabilities requested by the workflow are provided by the runners, there is match.  </p> <p>Examples:</p> Runner Labels Workflow runs-on: Result 'self-hosted', 'Linux', 'X64' self-hosted matches 'self-hosted', 'Linux', 'X64' Linux matches 'self-hosted', 'Linux', 'X64' X64 matches 'self-hosted', 'Linux', 'X64' [ self-hosted, Linux ] matches 'self-hosted', 'Linux', 'X64' [ self-hosted, X64 ] matches 'self-hosted', 'Linux', 'X64' [ self-hosted, Linux, X64 ] matches 'self-hosted', 'Linux', 'X64' other1 no match 'self-hosted', 'Linux', 'X64' [ self-hosted, other2 ] no match 'self-hosted', 'Linux', 'X64' [ self-hosted, Linux, X64, other2 ] no match 'self-hosted', 'Linux', 'X64', 'custom3' custom3 matches 'self-hosted', 'Linux', 'X64', 'custom3' [ custom3, Linux ] matches 'self-hosted', 'Linux', 'X64', 'custom3' [ custom3, X64 ] matches 'self-hosted', 'Linux', 'X64', 'custom3' [ custom3, other7 ] no match <p>If default labels are removed:</p> Runner Labels Workflow runs-on: Result 'custom5' custom5 matches 'custom5' self-hosted no match 'custom5' Linux no match 'custom5' [ self-hosted, Linux ] no match 'custom5' [ custom5, self-hosted, Linux ] no match"},{"location":"configuration/","title":"Configuration","text":""},{"location":"configuration/#configuration-considerations","title":"Configuration considerations","text":"<p>To be able to support a number of use-cases, the module has quite a lot of configuration options. We tried to choose reasonable defaults. Several examples also show the main cases of how to configure the runners.</p> <ul> <li>Org vs Repo level. You can configure the module to connect the runners in GitHub on an org level and share the runners in your org, or set the runners on repo level and the module will install the runner to the repo. There can be multiple repos but runners are not shared between repos.</li> <li>Multi-Runner module. This modules allows you to create multiple runner configurations with a single webhook and single GitHub App to simplify deployment of different types of runners. Check the detailed module documentation for more information or checkout the multi-runner example.</li> <li>Webhook mode, the module can be deployed in <code>direct</code> mode or <code>EventBridge</code> (Experimental) mode. The <code>direct</code> mode is the default and will directly distribute to SQS for the scale-up lambda. The <code>EventBridge</code> mode will publish the events to a eventbus, the rule then directs the received events to a dispatch lambda. The dispatch lambda will send the event to the SQS queue. The <code>EventBridge</code> mode is the default and allows to have more control over the events and potentially filter them. The <code>EventBridge</code> mode can be disabled, messages are sent directed to queues in that case. An example of what the <code>EventBridge</code> mode could be used for is building a data lake, build metrics, act on <code>workflow_job</code> job started events, etc.</li> <li>Linux vs Windows. You can configure the OS types linux and win. Linux will be used by default.</li> <li>Re-use vs Ephemeral. By default runners are re-used, until detected idle. Once idle they will be removed from the pool. To improve security we are introducing ephemeral runners. Those runners are only used for one job. Ephemeral runners only work in combination with the workflow job event. For ephemeral runners the lambda requests a JIT (just in time) configuration via the GitHub API to register the runner. JIT configuration is limited to ephemeral runners (and currently not supported by GHES). For non-ephemeral runners, a registration token is always requested. In both cases the configuration is made available to the instance via the same SSM parameter. To disable JIT configuration for ephemeral runners set <code>enable_jit_config</code> to <code>false</code>. We also suggest using a pre-build AMI to improve the start time of jobs for ephemeral runners.</li> <li>Job retry (Beta). By default the scale-up lambda will discard the message when it is handled. Meaning in the ephemeral use-case an instance is created. The created runner will ask GitHub for a job, no guarantee it will run the job for which it was scaling. Result could be that with small system hick-up the job is keeping waiting for a runner. Enable a pool (org runners) is one option to avoid this problem. Another option is to enable the job retry function. Which will retry the job after a delay for a configured number of times.</li> <li>GitHub Cloud vs GitHub Enterprise Server (GHES). The runners support GitHub Cloud as well GitHub Enterprise Server. For GHES, we rely on our community for support and testing. We have no capability to test GHES ourselves.</li> <li>Spot vs on-demand. The runners use either the EC2 spot or on-demand life cycle. Runners will be created via the AWS CreateFleet API. The module (scale up lambda) will request via the CreateFleet API to create instances in one of the subnets and of the specified instance types.</li> <li>ARM64 support via Graviton/Graviton2 instance-types. When using the default example or top-level module, specifying <code>instance_types</code> that match a Graviton/Graviton 2 (ARM64) architecture (e.g. a1, t4g or any 6th-gen <code>g</code> or <code>gd</code> type), you must also specify <code>runner_architecture = \"arm64\"</code> and the sub-modules will be automatically configured to provision with ARM64 AMIs and leverage GitHub's ARM64 action runner. See below for more details.</li> <li>Disable default labels for the runners (os, architecture and <code>self-hosted</code>) can achieve by setting <code>runner_disable_default_labels</code> = true. If enabled, the runner will only have the extra labels provided in <code>runner_extra_labels</code>. In case you on own start script is used, this configuration parameter needs to be parsed via SSM.</li> </ul>"},{"location":"configuration/#aws-ssm-parameters","title":"AWS SSM Parameters","text":"<p>The module uses the AWS System Manager Parameter Store to store configuration for the runners, as well as registration tokens and secrets for the Lambdas. Paths for the parameters can be configured via the variable <code>ssm_paths</code>. The location of the configuration parameters is retrieved by the runners via the instance tag <code>ghr:ssm_config_path</code>. The following default paths will be used. Tokens or JIT config stored in the token path will be deleted after retrieval by instance, data not deleted after a day will be deleted by a SSM housekeeper lambda.</p> Path Description <code>ssm_paths.root/var.prefix?/app/</code> App secrets used by Lambda's <code>ssm_paths.root/var.prefix?/runners/config/&lt;name&gt;</code> Configuration parameters used by runner start script <code>ssm_paths.root/var.prefix?/runners/tokens/&lt;ec2-instance-id&gt;</code> Either JIT configuration (ephemeral runners) or registration tokens (non ephemeral runners) generated by the control plane (scale-up lambda), and consumed by the start script on the runner to activate / register the runner. <code>ssm_paths.root/var.prefix?/webhook/runner-matcher-config</code> Runner matcher config used by webhook to decide the target for the webhook event. <p>Available configuration parameters:</p> Parameter name Description <code>agent_mode</code> Indicates if the agent is running in ephemeral mode or not. <code>disable_default_labels</code> Indicates if the default labels for the runners (os, architecture and <code>self-hosted</code>) are disabled <code>enable_cloudwatch</code> Configuration for the cloudwatch agent to stream logging. <code>run_as</code> The user used for running the GitHub action runner agent. <code>token_path</code> The path where tokens are stored."},{"location":"configuration/#encryption","title":"Encryption","text":"<p>The module supports two scenarios to manage environment secrets and private keys of the Lambda functions.</p>"},{"location":"configuration/#managed-kms-key-default","title":"Managed KMS key (default)","text":"<p>This is the default, no additional configuration is required.</p>"},{"location":"configuration/#provided-kms-key","title":"Provided KMS key","text":"<p>You have to create and configure you KMS key. The module will use the context with key: <code>Environment</code> and value <code>var.environment</code> as encryption context.</p> <pre><code>resource \"aws_kms_key\" \"github\" {\n  is_enabled = true\n}\n\nmodule \"runners\" {\n\n  ...\n  kms_key_arn = aws_kms_key.github.arn\n  ...\n</code></pre>"},{"location":"configuration/#pool","title":"Pool","text":"<p>The module supports two options for keeping a pool of runners. One is via a pool which only supports org-level runners, the second option is keeping runners idle.</p> <p>The pool is introduced in combination with the ephemeral runners and is primarily meant to ensure if any event is unexpectedly dropped and no runner was created, the pool can pick up the job. The pool is maintained by a lambda. Each time the lambda is triggered a check is performed to ensure the number of idle runners managed by the module matches the expected pool size. If not, the pool will be adjusted. Keep in mind that the scale down function is still active and will terminate instances that are detected as idle.</p> <pre><code>pool_runner_owner = \"my-org\"                  # Org to which the runners are added\npool_config = [{\n  size                         = 20                    # size of the pool\n  schedule_expression          = \"cron(* * * * ? *)\"   # cron expression to trigger the adjustment of the pool\n  schedule_expression_timezone = \"Australia/Sydney\"    # optional time zone (defaults to UTC)\n}]\n</code></pre> <p>The pool is NOT enabled by default and can be enabled by setting at least one object of the pool config list. The ephemeral example contains configuration options (commented out).</p>"},{"location":"configuration/#idle-runners","title":"Idle runners","text":"<p>The module will scale down to zero runners by default. By specifying a <code>idle_config</code> config, idle runners can be kept active. The scale down lambda checks if any of the cron expressions matches the current time with a margin of 5 seconds. When there is a match, the number of runners specified in the idle config will be kept active. In case multiple cron expressions match, the first one will be used. Below is an idle configuration for keeping runners active from 9:00am to 5:59pm on working days. The cron expression generator by Cronhub is a great resource to set up your idle config.</p> <p>By default, the oldest instances are evicted. This helps keep your environment up-to-date and reduce problems like running out of disk space or RAM. Alternatively, if your older instances have a long-living cache, you can override the <code>evictionStrategy</code> to <code>newest_first</code> to evict the newest instances first instead.</p> <pre><code>idle_config = [{\n   cron             = \"* * 9-17 * * 1-5\"\n   timeZone         = \"Europe/Amsterdam\"\n   idleCount        = 2\n   # Defaults to 'oldest_first'\n   evictionStrategy = \"oldest_first\"\n}]\n</code></pre> <p>Note: When using Windows runners, we recommend keeping a few runners warmed up due to the minutes-long cold start time.</p>"},{"location":"configuration/#supported-config","title":"Supported config","text":"<p>Cron expressions are parsed by cron-parser. The supported syntax.</p> <pre><code>*    *    *    *    *    *\n\u252c    \u252c    \u252c    \u252c    \u252c    \u252c\n\u2502    \u2502    \u2502    \u2502    \u2502    |\n\u2502    \u2502    \u2502    \u2502    \u2502    \u2514 day of week (0 - 7) (0 or 7 is Sun)\n\u2502    \u2502    \u2502    \u2502    \u2514\u2500\u2500\u2500\u2500\u2500 month (1 - 12)\n\u2502    \u2502    \u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 day of month (1 - 31)\n\u2502    \u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 hour (0 - 23)\n\u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 minute (0 - 59)\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 second (0 - 59, optional)\n</code></pre> <p>For time zones please check TZ database name column for the supported values.</p>"},{"location":"configuration/#ephemeral-runners","title":"Ephemeral runners","text":"<p>You can configure runners to be ephemeral, in which case runners will be used only for one job. The feature should be used in conjunction with listening for the workflow job event. Please consider the following:</p> <ul> <li>The scale down lambda is still active, and should only remove orphan instances. But there is no strict check in place. So ensure you configure the <code>minimum_running_time_in_minutes</code> to a value that is high enough to get your runner booted and connected to avoid it being terminated before executing a job.</li> <li>The messages sent from the webhook lambda to the scale-up lambda are by default delayed by SQS, to give available runners a chance to start the job before the decision is made to scale more runners. For ephemeral runners there is no need to wait. Set <code>delay_webhook_event</code> to <code>0</code>.</li> <li>All events in the queue will lead to a new runner created by the lambda. By setting <code>enable_job_queued_check</code> to <code>true</code> you can enforce a rule of only creating a runner if the event has a correlated queued job. Setting this can avoid creating useless runners. For example, a job getting cancelled before a runner was created or if the job was already picked up by another runner. We suggest using this in combination with a pool.</li> <li>Errors related to scaling should be retried via SQS. You can configure <code>job_queue_retention_in_seconds</code> and <code>redrive_build_queue</code> to tune the behavior. We have no mechanism to avoid events never being processed, which means potentially no runner gets created and the job in GitHub times out in 6 hours.</li> </ul> <p>The example for ephemeral runners is based on the default example. Have look at the diff to see the major configuration differences.</p>"},{"location":"configuration/#job-retry-beta","title":"Job retry (Beta)","text":"<p>You can enable the job retry function to retry a job after a delay for a configured number of times. The function is disabled by default. To enable the function set <code>job_retry.enable</code> to <code>true</code>. The function will check the job status after a delay, and when the is still queued, it will create a new runner. The new runner is created in the same way as the others via the scale-up function. Hence the same configuration applies.</p> <p>For checking the job status a API call is made to GitHub. Which can exhaust the GitHub API more quickly for larger deployments and cause rate limits. For larger deployment with a lot of frequent jobs having a small pool available could be a better choice.</p> <p>The option <code>job_retry.delay_in_seconds</code> is the delay before the job status is checked. The delay is increased by the factor <code>job_retry.delay_backoff</code> for each attempt. The upper bound for a delay is 900 seconds, which is the max message delay on SQS. The maximum number of attempts is configured via <code>job_retry.max_attempts</code>. The delay should be set to a higher value than the time it takes to start a runner.</p>"},{"location":"configuration/#prebuilt-images","title":"Prebuilt Images","text":"<p>This module also allows you to run agents from a prebuilt AMI to gain faster startup times. The module provides several examples to build your own custom AMI. To remove old images, an AMI housekeeper module can be used. See the AMI examples for more details.</p>"},{"location":"configuration/#logging","title":"Logging","text":"<p>The module uses AWS Lambda Powertools for logging. By default the log level is set to <code>info</code>, by setting the log level to <code>debug</code> the incoming events of the Lambda are logged as well.</p> <p>Log messages contains at least the following keys:</p> <ul> <li><code>messages</code>: The logged messages</li> <li><code>environment</code>: The environment prefix provided via Terraform</li> <li><code>service</code>: The lambda</li> <li><code>module</code>: The TypeScript module writing the log message</li> <li><code>function-name</code>: The name of the lambda function (prefix + function name)</li> <li><code>github</code>: Depending on the lambda, contains GitHub context</li> <li><code>runner</code>: Depending on the lambda, specific context related to the runner</li> </ul> <p>An example log message of the scale-up function:</p> <pre><code>{\n  \"level\": \"INFO\",\n  \"message\": \"Received event\",\n  \"service\": \"runners-scale-up\",\n  \"timestamp\": \"2023-03-20T08:15:27.448Z\",\n  \"xray_trace_id\": \"1-6418161e-08825c2f575213ef760531bf\",\n  \"module\": \"scale-up\",\n  \"region\": \"eu-west-1\",\n  \"environment\": \"my-linux-x64\",\n  \"aws-request-id\": \"eef1efb7-4c07-555f-9a67-b3255448ee60\",\n  \"function-name\": \"my-linux-x64-scale-up\",\n  \"runner\": {\n    \"type\": \"Repo\",\n    \"owner\": \"test-runners/multi-runner\"\n  },\n  \"github\": {\n    \"event\": \"workflow_job\",\n    \"workflow_job_id\": \"1234\"\n  }\n}\n</code></pre>"},{"location":"configuration/#tracing","title":"Tracing","text":"<p>The distributed architecture of this application can make it difficult to troubleshoot. We support the option to enable tracing for all the lambda functions created by this application. To enable tracing, you can provide the <code>tracing_config</code> option inside the root module or inner modules.</p> <p>This tracing config generates timelines for following events:</p> <ul> <li>Basic lifecycle of lambda function</li> <li>Traces for Github API calls (can be configured by capture_http_requests).</li> <li>Traces for all AWS SDK calls</li> </ul> <p>This feature has been disabled by default.</p>"},{"location":"configuration/#multiple-runner-module-in-your-aws-account","title":"Multiple runner module in your AWS account","text":"<p>The watcher will act on all spot termination notificatins and log all onses relevant to the runner module. Therefor we suggest to only deploy the watcher once. You can either deploy the watcher by enabling in one of your deployments or deploy the watcher as a stand alone module.</p>"},{"location":"configuration/#metrics","title":"Metrics","text":"<p>The module supports metrics (experimental feature) to monitor the system. The metrics are disabled by default. To enable the metrics set <code>metrics.enable = true</code>. If set to true, all module managed metrics are used, you can configure the one by one via the <code>metrics</code> object. The metrics are created in the namespace <code>GitHub Runners</code>.</p>"},{"location":"configuration/#supported-metrics","title":"Supported metrics","text":"<ul> <li>GitHubAppRateLimitRemaining: Remaining rate limit for the GitHub App.</li> <li>JobRetry: Number of job retries, only relevant when job retry is enabled.</li> <li>SpotInterruptionWarning: Number of spot interruption warnings received by the termination watcher, only relevant when the termination watcher is enabled.</li> </ul>"},{"location":"configuration/#debugging","title":"Debugging","text":"<p>In case the setup does not work as intended, trace the events through this sequence:</p> <ul> <li>In the GitHub App configuration, the Advanced page displays all webhook events that were sent.</li> <li>In AWS CloudWatch, every lambda has a log group. Look at the logs of the <code>webhook</code> and <code>scale-up</code> lambdas.</li> <li>In AWS SQS you can see messages available or in flight.</li> <li>Once an EC2 instance is running, you can connect to it in the EC2 user interface using Session Manager (use <code>enable_ssm_on_runners = true</code>). Check the user data script using <code>cat /var/log/user-data.log</code>. By default several log files of the instances are streamed to AWS CloudWatch, look for a log group named <code>&lt;environment&gt;/runners</code>. In the log group you should see at least the log streams for the user data installation and runner agent.</li> <li>Registered instances should show up in the Settings - Actions page of the repository or organization (depending on the installation mode).</li> </ul>"},{"location":"configuration/#experimental-features","title":"Experimental features","text":""},{"location":"configuration/#termination-watcher","title":"Termination watcher","text":"<p>This feature is in early stage and therefore disabled by default. To enable the watcher, set <code>instance_termination_watcher.enable = true</code>.</p> <p>The termination watcher is currently watching for spot terminations. The module is only taken events into account for instances tagged with <code>ghr:environment</code> by default when deployment the module as part of one of the main modules (root or multi-runner). The module can also be deployed stand-alone, in this case, the tag filter needs to be tunned.</p>"},{"location":"configuration/#termination-notification","title":"Termination notification","text":"<p>The watcher is listening for spot termination warnings and create a log message and optionally a metric. The watcher is disabled by default. The feature is enabled once the watcher is enabled, the feature can be disabled explicit by setting <code>instance_termination_watcher.features.enable_spot_termination_handler = false</code>.</p> <ul> <li>Logs: The module will log all termination notifications. For each warning it will look up instance details and log the environment, instance type and time the instance is running. As well some other details.</li> <li>Metrics: Metrics are disabled by default, this to avoid costs. Once enabled a metric will be created for each warning with at least dimensions for the environment and instance type. THe metric name space can be configured via the variables. The metric name used is <code>SpotInterruptionWarning</code>.</li> </ul>"},{"location":"configuration/#termination-handler","title":"Termination handler","text":"<p>Warning</p> <p>This feature will only work once the CloudTrail is enabled.</p> <p>The termination handler is listening for spot terminations by capture the <code>BidEvictedEvent</code> via CloudTrail. The handler will log and optionally create a metric for each termination. The intend is to enhance the logic to inform the user about the termination via the GitHub Job or Workflow run. The feature is disabled by default. The feature is enabled once the watcher is enabled, the feature can be disabled explicit by setting <code>instance_termination_watcher.features.enable_spot_termination_handler = false</code>.</p> <ul> <li>Logs: The module will log all termination notifications. For each warning it will look up instance details and log the environment, instance type and time the instance is running. As well some other details.</li> <li>Metrics: Metrics are disabled by default, this to avoid costs. Once enabled a metric will be created for each termination with at least dimensions for the environment and instance type. THe metric name space can be configured via the variables. The metric name used is <code>SpotTermination</code>.</li> </ul>"},{"location":"configuration/#log-example-both-warnings-and-terminations","title":"Log example (both warnings and terminations)","text":"<p>Below an example of the the log messages created.</p> <pre><code>{\n    \"level\": \"INFO\",\n    \"message\": \"Received spot notification for ${metricName}\",\n    \"environment\": \"default\",\n    \"instanceId\": \"i-0039b8826b3dcea55\",\n    \"instanceType\": \"c5.large\",\n    \"instanceLaunchTime\": \"2024-03-15T08:10:34.000Z\",\n    \"instanceRunningTimeInSeconds\": 68,\n    \"tags\": [\n        {\n            \"Key\": \"ghr:environment\",\n            \"Value\": \"default\"\n        }\n        ... all tags ...\n    ]\n}\n</code></pre>"},{"location":"configuration/#eventbridge","title":"EventBridge","text":"<p>This module can be deployed in using the mode <code>EventBridge</code>. The <code>EventBridge</code> mode will publish an event to a eventbus. Within the eventbus, there is a target rule set, sending events to the dispatch lambda. The <code>EventBridge</code> mode is enabled by default.</p> <p>Example to extend the EventBridge:</p> <pre><code>module \"runners\" {\n  source = \"github-aws-runners/github-runners/aws\"\n\n  ...\n  eventbridge = {\n    enable = false\n  }\n  ...\n}\n\nlocals {\n  event_bus_name = module.runners.webhook.eventbridge.event_bus.name\n}\n\nresource \"aws_cloudwatch_event_rule\" \"example\" {\n  name           = \"${local.prefix}-github-events-all\"\n  description    = \"Caputure all GitHub events\"\n  event_bus_name = local.event_bus_name\n  event_pattern  = &lt;&lt;EOF\n{\n  \"source\": [{\n    \"prefix\": \"github\"\n  }]\n}\nEOF\n}\n\nresource \"aws_cloudwatch_event_target\" \"main\" {\n  rule           = aws_cloudwatch_event_rule.example.name\n  arn            = &lt;arn of target&gt;\n  event_bus_name = local.event_bus_name\n  role_arn       = aws_iam_role.event_rule_firehose_role.arn\n}\n\ndata \"aws_iam_policy_document\" \"event_rule_firehose_role\" {\n  statement {\n    actions = [\"sts:AssumeRole\"]\n\n    principals {\n      type        = \"Service\"\n      identifiers = [\"events.amazonaws.com\"]\n    }\n  }\n}\n\nresource \"aws_iam_role\" \"event_rule_role\" {\n  name               = \"${local.prefix}-eventbridge-github-rule\"\n  assume_role_policy = data.aws_iam_policy_document.event_rule_firehose_role.json\n}\n\ndata aws_iam_policy_document firehose_stream {\n  statement {\n    INSER_YOUR_POIICY_HERE_TO_ACCESS_THE_TARGET\n  }\n}\n\nresource \"aws_iam_role_policy\" \"event_rule_firehose_role\" {\n  name = \"target-event-rule-firehose\"\n  role = aws_iam_role.event_rule_firehose_role.name\n  policy = data.aws_iam_policy_document.firehose_stream.json\n}\n</code></pre> <p>NOTE: By default, a runner AMI update requires a re-apply of this terraform config (the runner AMI ID is looked up by a terraform data source). To avoid this, you can use <code>ami_id_ssm_parameter_name</code> to have the scale-up lambda dynamically lookup the runner AMI ID from an SSM parameter at instance launch time. Said SSM parameter is managed outside of this module (e.g. by a runner AMI build workflow).</p>"},{"location":"getting-started/","title":"Getting started","text":"<p>Terraform examples are available for different use-cases for example multiple runners, ephemeral runners, and windows. For more details see the examples.</p> <p>The module supports two main scenarios for creating runners. Repository level runners will be dedicated to only one repository, no other repository can use the runner. At the organization level you can use the runner(s) for all repositories within the organization. See GitHub self-hosted runner instructions for more information. Before starting the deployment you have to choose one option.</p> <p>The setup guide below is a generic direction. There are many choices you can make, and there is no right way. For example we deploy ephemeral runners for both Linux and WIndows with packer pre-built AMI's that are automatically updated. Deployment is done with GitHub actions, Terragrunt and terraform. The lambda's we sync to AWS S3. For the major fleet we have a tiny pool to let start jobs quickly.</p>"},{"location":"getting-started/#required-tools","title":"Required tools","text":"<p>The following tools are a minimum requirement. We advise to deploy the stack via a CI/CD pipeline.</p> <ul> <li>Terraform</li> <li>Bash shell or compatible</li> <li>Docker (optional, to build lambdas without node).</li> <li>AWS cli (optional)</li> <li>Node and yarn to build the Lambda's (or download via Release).</li> </ul>"},{"location":"getting-started/#setup-guide","title":"Setup guide","text":"<p>The setup consists of running Terraform to create all AWS resources and manually configuring the GitHub App. The Terraform module requires configuration from the GitHub App and the GitHub app requires output from Terraform. Therefore you first create the GitHub App and configure the basics, then run Terraform, and afterwards finalize the configuration of the GitHub App.</p>"},{"location":"getting-started/#setup-github-app-part-1","title":"Setup GitHub App (part 1)","text":"<p>Go to GitHub and create a new app. Be aware you can create apps for your organization or for a user. For now we only support organization level apps.</p> <ol> <li>Create an app in Github</li> <li>Choose a name</li> <li>Choose a website (mandatory, not required for the module).</li> <li>Disable the webhook for now (we will configure this later or create an alternative webhook).</li> <li>Permissions for all runners:<ul> <li>Repository:</li> <li><code>Actions</code>: Read-only (check for queued jobs)</li> <li><code>Checks</code>: Read-only (receive events for new builds)</li> <li><code>Metadata</code>: Read-only (default/required)</li> </ul> </li> <li>Permissions for repo level runners only:</li> <li>Repository:<ul> <li><code>Administration</code>: Read &amp; write (to register runner)</li> </ul> </li> <li>Permissions for organization level runners only:</li> <li>Organization<ul> <li><code>Self-hosted runners</code>: Read &amp; write (to register runner)</li> </ul> </li> <li>Save the new app.</li> <li>On the General page, make a note of the \"App ID\" and \"Client ID\" parameters.</li> <li>Generate a new private key and save the <code>app.private-key.pem</code> file.</li> </ol>"},{"location":"getting-started/#setup-terraform-module","title":"Setup terraform module","text":""},{"location":"getting-started/#download-lambdas","title":"Download lambdas","text":"<p>To apply the terraform module, the compiled lambdas (.zip files) need to be available either locally or in an S3 bucket. They can either be downloaded from the GitHub release page or built locally.</p> <p>To read the files from S3, set the <code>lambda_s3_bucket</code> variable and the specific object key for each lambda.</p> <p>The lambdas can be downloaded manually from the release page or using the download-lambda terraform module (requires <code>curl</code> to be installed on your machine). In the <code>download-lambda</code> directory, run <code>terraform init &amp;&amp; terraform apply</code>. The lambdas will be saved to the same directory.</p> <p>For local development you can build all the lambdas at once using <code>.ci/build.sh</code> or individually using <code>yarn dist</code>.</p>"},{"location":"getting-started/#service-linked-role","title":"Service-linked role","text":"<p>To create spot instances the <code>AWSServiceRoleForEC2Spot</code> role needs to be added to your account. You can do that manually by following the AWS docs. To use terraform for creating the role, either add the following resource or let the module manage the service linked role by setting <code>create_service_linked_role_spot</code> to <code>true</code>. Be aware this is an account global role, so maybe you don't want to manage it via a specific deployment.</p> <pre><code>resource \"aws_iam_service_linked_role\" \"spot\" {\n  aws_service_name = \"spot.amazonaws.com\"\n}\n</code></pre>"},{"location":"getting-started/#terraform-module","title":"Terraform module","text":"<p>Next create a second terraform workspace and initiate the module, or adapt one of the examples.</p> <p>Note that <code>github_app.key_base64</code> needs to be a base64-encoded string of the <code>.pem</code> file i.e. the output of <code>base64 app.private-key.pem</code>. The decoded string can either be a multiline value or a single line value with new lines represented with literal <code>\\n</code> characters.</p> <pre><code>module \"github-runner\" {\n  source  = \"github-aws-runners/github-runner/aws\"\n  version = \"REPLACE_WITH_VERSION\"\n\n  aws_region = \"eu-west-1\"\n  vpc_id     = \"vpc-123\"\n  subnet_ids = [\"subnet-123\", \"subnet-456\"]\n\n  prefix = \"gh-ci\"\n\n  github_app = {\n    key_base64     = \"base64string\"\n    id             = \"1\"\n    webhook_secret = \"webhook_secret\"\n  }\n\n  webhook_lambda_zip                = \"lambdas-download/webhook.zip\"\n  runner_binaries_syncer_lambda_zip = \"lambdas-download/runner-binaries-syncer.zip\"\n  runners_lambda_zip                = \"lambdas-download/runners.zip\"\n  enable_organization_runners = true\n}\n</code></pre> <p>Run terraform by using the following commands</p> <pre><code>terraform init\nterraform apply\n</code></pre> <p>The terraform output displays the API gateway url (endpoint) and secret, which you need in the next step.</p> <p>The lambda for syncing the GitHub distribution to S3 is triggered via CloudWatch (by default once per hour). After deployment the function is triggered via S3 to ensure the distribution is cached.</p>"},{"location":"getting-started/#setup-the-webhook-github-app-part-2","title":"Setup the webhook / GitHub App (part 2)","text":"<p>At this point you have two options. Either create a separate webhook (enterprise, org, or repo), or create a webhook in the App.</p>"},{"location":"getting-started/#option-1-webhook","title":"Option 1: Webhook","text":"<ol> <li>Create a new webhook at the repo level for repo level runners, or org (or enterprise level) for org level runners.</li> <li>Provide the webhook url, which should be part of the output of terraform.</li> <li>Provide the webhook secret (<code>terraform output -raw &lt;NAME_OUTPUT_VAR&gt;</code>).</li> <li>Ensure the content type is <code>application/json</code>.</li> <li>In the \"Permissions &amp; Events\" section and then \"Subscribe to Events\" subsection, check either \"Workflow Job\" or \"Check Run\" (choose only one option!!!).</li> <li>In the \"Install App\" section, install the App in your organization, either in all or in selected repositories.</li> </ol>"},{"location":"getting-started/#option-2-app","title":"Option 2: App","text":"<p>Go back to the GitHub App and update the following settings.</p> <ol> <li>Enable the webhook.</li> <li>Provide the webhook url, should be part of the output of terraform.</li> <li>Provide the webhook secret (<code>terraform output -raw &lt;NAME_OUTPUT_VAR&gt;</code>).</li> <li>In the \"Permissions &amp; Events\" section and then \"Subscribe to Events\" subsection, check either \"Workflow Job\" or \"Check Run\" (choose only one option!!!).</li> </ol>"},{"location":"getting-started/#install-github-app","title":"Install GitHub app","text":"<p>Finally you need to ensure the app is installed to all or selected repositories.</p> <p>Go back to the GitHub App and update the following settings.</p> <ol> <li>In the \"Install App\" section, install the App in your organization, either in all or in selected repositories.</li> </ol>"},{"location":"getting-started/#debugging","title":"Debugging","text":"<p>In case the setup does not work as intended follow the trace of events:</p> <ul> <li>In the GitHub App configuration, the Advanced page displays all webhook events that were sent.</li> <li>In AWS CloudWatch, every lambda has a log group. Look at the logs of the <code>webhook</code> and <code>scale-up</code> lambdas.</li> <li>In AWS SQS you can see messages available or in flight.</li> <li>Once an EC2 instance is running, you can connect to it in the EC2 user interface using Session Manager (use <code>enable_ssm_on_runners = true</code>). Check the user data script using <code>cat /var/log/user-data.log</code>. By default several log files of the instances are streamed to AWS CloudWatch, look for a log group named <code>&lt;environment&gt;/runners</code>. In the log group you should see at least the log streams for the user data installation and runner agent.</li> <li>Registered instances should show up in the Settings - Actions page of the repository or organization (depending on the installation mode).</li> </ul>"},{"location":"security/","title":"Security","text":"<p>This module creates resources in your AWS infrastructure, and EC2 instances for hosting the self-hosted runners on-demand. IAM permissions are set to a minimal level, and could be further limited by using permission boundaries. Instances permissions are limited to retrieve and delete the registration token, access the instance's own tags, and terminate the instance itself. By nature instances are short-lived, we strongly suggest to use ephemeral runners to ensure a safe build environment for each workflow job execution.</p> <p>Ephemeral runners are using the JIT configuration, confguration that only can be used once to activate a runner. For non-ephemeral runners this option is not provided by GitHub. For non-ephemeeral runners a registration token is passed via SSM. After using the token, the token is deleted. But the token remains valid and is potential available in memory on the runner. For ephemeral runners this problem is avoid by using just in time tokens.</p> <p>The examples are using standard AMI's for different operation systems. Instances are not hardened, and sudo operation are not blocked. To provide an out of the box working experience by default the module installs and configures the runner. However secrets are not hard coded, they finally end up in the memory of the instances. You can harden the instance by providing your own AMI and overwriting the cloud-init script.</p> <p>We welcome any improvement to the standard module to make the default as secure as possible, in the end it remains your responsibility to keep your environment secure.</p>"},{"location":"ami-examples/","title":"Prebuilt Images","text":"<p> These images are provided as an example/</p> <p>The images inside this folder are pre-built images designed to shorten the boot time of your runners and make using ephemeral runners a faster experience.</p> <p>These images share the same scripting as used in the user-data mechanism in <code>/modules/runners/templates/</code>. We use a <code>templatefile</code> mechanism to insert the relevant script fragments into the scripts used for provisioning the images.</p> <p>The examples in <code>linux-al2023</code> and <code>windows-core-2019</code> also upload a <code>start-runner</code> script that uses the exact same startup process as used in the user-data mechanism. This means that the image created here does not need any extra scripts injected or changes to boot up and connect to GH.</p> <p>To remove old images the AMI house keeper module can be used.</p>"},{"location":"ami-examples/#building-your-own","title":"Building your own","text":"<p>To build these images you first need to install packer. You will also need an amazon account and to have provisioned your credentials for packer to consume.</p> <p>Assuming you are building the <code>linux-al2023</code> image. Then run the following from within the <code>linux-al2023</code> folder</p> <pre><code>packer init .\npacker validate .\npacker build github_agent.linux.pkr.hcl\n</code></pre> <p>Your image will then begin to build inside AWS and when finished you will be provided with complete AMI.</p>"},{"location":"ami-examples/#using-your-image","title":"Using your image","text":"<p>To use your image in the terraform modules you will need to set some values on the module.</p> <p>Assuming you have built the <code>linux-al2023</code> image which has a pre-defined AMI name in the following format <code>github-runner-al2023-x86_64-YYYYMMDDhhmm</code> you can use the following values.</p> <pre><code># set the name of the ami to use\nami_filter        = { name = [\"github-runner-al2023-x86_64-2023*\"] }\n# provide the owner id of\nami_owners        = [\"&lt;your owner id&gt;\"]\n\nenable_userdata = false\n</code></pre>"},{"location":"examples/","title":"Examples","text":"<p>Examples are located in the examples directory. The following examples are provided:</p> <ul> <li>Default: The default example of the module</li> <li>Ephemeral: Example usages of ephemeral runners based on the default example.</li> <li>Multi Runner : Example usage of creating a multi runner which creates multiple runners/ configurations with a single deployment. The examples including: \"arm64\", \"windows\", and \"ubuntu\" runners.</li> <li>Permissions boundary: Example usages of permissions boundaries.</li> <li>Prebuilt Images: Example usages of deploying runners with a custom prebuilt image.</li> <li>Windows: Example usage of creating a runner using Windows as the OS.</li> <li>Termination watcher: Example usages of termination watcher.</li> </ul>"},{"location":"examples/default/","title":"Amazon Linux X64 (default)","text":"<p>This module shows how to create GitHub action runners. Lambda release will be downloaded from GitHub.</p>"},{"location":"examples/default/#usages","title":"Usages","text":"<p>Steps for the full setup, such as creating a GitHub app can be found in the root module's README. First download the Lambda releases from GitHub. Alternatively you can build the lambdas locally with Node or Docker, there is a simple build script in <code>&lt;root&gt;/.ci/build.sh</code>. In the <code>main.tf</code> you can simply remove the location of the lambda zip files, the default location will work in this case.</p> <p>The default example assumes local built lambda's available. Ensure you have built the lambda's. Alternativly you can downlowd the lambda's. The version needs to be set to a GitHub release version, see https://github.com/github-aws-runners/terraform-aws-github-runner/releases</p> <pre><code>cd ../lambdas-download\nterraform init\nterraform apply -var=module_version=&lt;VERSION&gt;\ncd -\n</code></pre> <p>Before running Terraform, ensure the GitHub app is configured. See the configuration details for more details.</p> <pre><code>terraform init\nterraform apply\n</code></pre> <p>The example will try to update the webhook of your GitHub. In case the update fails the apply will not fail. You can receive the webhook details by running:</p> <pre><code>terraform output -raw webhook_secret\n</code></pre>"},{"location":"examples/default/#requirements","title":"Requirements","text":"Name Version terraform &gt;= 1.3.0 aws ~&gt; 5.27 local ~&gt; 2.0 random ~&gt; 3.0"},{"location":"examples/default/#providers","title":"Providers","text":"Name Version random 3.6.3"},{"location":"examples/default/#modules","title":"Modules","text":"Name Source Version base ../base n/a runners ../../ n/a webhook_github_app ../../modules/webhook-github-app n/a"},{"location":"examples/default/#resources","title":"Resources","text":"Name Type random_id.random resource"},{"location":"examples/default/#inputs","title":"Inputs","text":"Name Description Type Default Required aws_region AWS region. <code>string</code> <code>\"eu-west-1\"</code> no environment Environment name, used as prefix. <code>string</code> <code>null</code> no github_app GitHub for API usages. <pre>object({    id         = string    key_base64 = string  })</pre> n/a yes"},{"location":"examples/default/#outputs","title":"Outputs","text":"Name Description runners n/a webhook_endpoint n/a webhook_secret n/a"},{"location":"examples/ephemeral/","title":"Ephemeral Amazon Linux xX64","text":"<p>This example is based on the default setup, but shows how runners can be used with the ephemeral flag enabled. Once enabled, ephemeral runners will be used for one job only. Each job requires a fresh instance. This feature should be used in combination with the <code>workflow_job</code> event. See GitHub webhook endpoint configuration(link needed here). It is also suggested to use a pre-build AMI to minimize runner launch times.</p>"},{"location":"examples/ephemeral/#usages","title":"Usages","text":"<p>Steps for the full setup, such as creating a GitHub app can be found the docs. First download the Lambda releases from GitHub. Alternatively you can build the lambdas locally with Node or Docker, there is a simple build script in <code>&lt;root&gt;/.ci/build.sh</code>. In the <code>main.tf</code> you can simply remove the location of the lambda zip files, the default location will work in this case.</p> <p>Ensure you have set the version in <code>lambdas-download/main.tf</code> for running the example. The version needs to be set to a GitHub release version, see https://github.com/github-aws-runners/terraform-aws-github-runner/releases</p> <pre><code>cd lambdas-download\nterraform init\nterraform apply\ncd ..\n</code></pre> <p>Before running Terraform, ensure the GitHub app is configured. See the configuration details for more details.</p> <pre><code>terraform init\nterraform apply\n</code></pre> <p>The module will try to update the GitHub App webhook and secret (only linux/mac). You can receive the webhook details by running:</p> <pre><code>terraform output webhook_secret\n</code></pre>"},{"location":"examples/ephemeral/#requirements","title":"Requirements","text":"Name Version terraform &gt;= 1.3.0 aws ~&gt; 5.27 local ~&gt; 2.0 random ~&gt; 3.0"},{"location":"examples/ephemeral/#providers","title":"Providers","text":"Name Version random 3.6.3"},{"location":"examples/ephemeral/#modules","title":"Modules","text":"Name Source Version base ../base n/a runners ../../ n/a webhook_github_app ../../modules/webhook-github-app n/a"},{"location":"examples/ephemeral/#resources","title":"Resources","text":"Name Type random_id.random resource"},{"location":"examples/ephemeral/#inputs","title":"Inputs","text":"Name Description Type Default Required aws_region AWS region. <code>string</code> <code>\"eu-west-1\"</code> no environment Environment name, used as prefix <code>string</code> <code>null</code> no github_app GitHub for API usages. <pre>object({    id         = string    key_base64 = string  })</pre> n/a yes"},{"location":"examples/ephemeral/#outputs","title":"Outputs","text":"Name Description runners n/a webhook_endpoint n/a webhook_secret n/a"},{"location":"examples/lambda-download/","title":"Wrapper module to download lambda's for running the examples","text":"<p>Module is used by examples to download Lambda distribution from the GitHub release.</p> <pre><code>terraform init\nterraform apply -var=module_version=&lt;VERSION&gt;\n</code></pre>"},{"location":"examples/lambda-download/#requirements","title":"Requirements","text":"Name Version terraform &gt;= 1"},{"location":"examples/lambda-download/#providers","title":"Providers","text":"<p>No providers.</p>"},{"location":"examples/lambda-download/#modules","title":"Modules","text":"Name Source Version lambdas ../../modules/download-lambda n/a"},{"location":"examples/lambda-download/#resources","title":"Resources","text":"<p>No resources.</p>"},{"location":"examples/lambda-download/#inputs","title":"Inputs","text":"Name Description Type Default Required module_version Module release version. <code>string</code> n/a yes"},{"location":"examples/lambda-download/#outputs","title":"Outputs","text":"Name Description files n/a"},{"location":"examples/multi-runner/","title":"Action runners deployment of Multiple-Runner-Configurations-Together example","text":"<p>This module shows how to create GitHub action runners with multiple runner configuration together in one deployment. This example has the configurations for the following runner types with the relevant labels supported by them as matchers:</p> <ul> <li>Linux ARM64 <code>[\"self-hosted\", \"linux\", \"arm64\", \"amazon\"]</code>: Amazon Linux ARM64 non ephemeral runner based on module defaults</li> <li>Linux Ubuntu <code>[\"self-hosted\", \"linux\", \"x64\", \"ubuntu-latest\"]</code> or <code>[\"self-hosted\", \"linux\", \"x64\", \"ubuntu-2204\"]</code>: Ubuntu runners non ephemeral based on a custom start script.</li> <li>Linux X64 <code>[\"self-hosted\", \"linux\", \"x64\", \"amazon\"]</code>: Amazon X64 Linux runners ephemeral with retry enabled.</li> <li>Windows X64 <code>[\"self-hosted\", \"windows\", \"x64\", \"servercore-2022\"]</code>: Windows X64 Servercore 2022 runners non ephemeral based on a custom start script.</li> </ul> <p>The module will decide the runner for the workflow job based on the match in the labels defined in the workflow job and runner configuration. Also the runner configuration allows the match to be exact or non-exact match. We recommend to use only exact matches.</p> <p>For exact match, all the labels defined in the workflow should be present in the runner configuration matchers and for non-exact match, some of the labels in the workflow, when present in runner configuration, shall be enough for the runner configuration to be used for the job. First the exact matchers are applied, next the non exact ones.</p>"},{"location":"examples/multi-runner/#webhook","title":"Webhook","text":"<p>For the list of provided runner configurations, there will be a single webhook and only a single Github App to receive the notifications for all types of workflow triggers.</p>"},{"location":"examples/multi-runner/#lambda-distribution","title":"Lambda distribution","text":"<p>Per combination of OS and architecture a lambda distribution syncer will be created. For this example there will be three instances (windows X64, linux X64, linux ARM).</p>"},{"location":"examples/multi-runner/#usages","title":"Usages","text":"<p>Steps for the full setup, such as creating a GitHub app can be found the docs. First download the Lambda releases from GitHub. Alternatively you can build the lambdas locally with Node or Docker, there is a simple build script in <code>&lt;root&gt;/.ci/build.sh</code>. In the <code>main.tf</code> you can simply remove the location of the lambda zip files, the default location will work in this case.</p> <p>The default example assumes local built lambda's available. Ensure you have built the lambda's. Alternativly you can downlowd the lambda's. The version needs to be set to a GitHub release version, see https://github.com/github-aws-runners/terraform-aws-github-runner/releases</p> <pre><code>cd ../lambdas-download\nterraform init\nterraform apply -var=module_version=&lt;VERSION&gt;\ncd -\n</code></pre> <p>Before running Terraform, ensure the GitHub app is configured. See the configuration details for more details.</p> <pre><code>terraform init\nterraform apply\n</code></pre> <p>The example will try to update the webhook of your GitHub. In case the update fails the apply will not fail. You can receive the webhook details by running:</p> <pre><code>terraform output -raw webhook_secret\n</code></pre>"},{"location":"examples/multi-runner/#requirements","title":"Requirements","text":"Name Version terraform &gt;= 1.3.0 aws ~&gt; 5.27 local ~&gt; 2.0 random ~&gt; 3.0"},{"location":"examples/multi-runner/#providers","title":"Providers","text":"Name Version random 3.6.3"},{"location":"examples/multi-runner/#modules","title":"Modules","text":"Name Source Version base ../base n/a runners ../../modules/multi-runner n/a webhook_github_app ../../modules/webhook-github-app n/a"},{"location":"examples/multi-runner/#resources","title":"Resources","text":"Name Type random_id.random resource"},{"location":"examples/multi-runner/#inputs","title":"Inputs","text":"Name Description Type Default Required aws_region AWS region to deploy to <code>string</code> <code>\"eu-west-1\"</code> no environment Environment name, used as prefix <code>string</code> <code>null</code> no github_app GitHub for API usages. <pre>object({    id         = string    key_base64 = string  })</pre> n/a yes"},{"location":"examples/multi-runner/#outputs","title":"Outputs","text":"Name Description webhook_endpoint n/a webhook_secret n/a"},{"location":"examples/permissions-boundary/","title":"Action runners deployed with permissions boundary","text":"<p>This module shows how to create GitHub action runners with permissions boundaries and paths used in role, policies, and instance profiles.</p>"},{"location":"examples/permissions-boundary/#usages","title":"Usages","text":"<pre><code>cd setup\nterraform init\nterraform apply\ncd ..\n</code></pre> <p>Now a new role and policies should be created. The output of the previous step is imported in this workspace to load the role and policy. The deployment of the runner module assumes the new role before creating all resources (https://www.terraform.io/docs/providers/aws/index.html#assume-role). Before running Terraform, ensure the GitHub app is configured.</p> <p>Download the lambda releases.</p> <pre><code>cd ../lambdas-download\nterraform init\nterraform apply -var=module_version=&lt;VERSION&gt;\ncd -\n</code></pre> <p>Now you can deploy the module.</p> <pre><code>terraform init\nterraform apply\n</code></pre>"},{"location":"examples/permissions-boundary/#requirements","title":"Requirements","text":"Name Version terraform &gt;= 1.3.0 aws ~&gt; 5.27 local ~&gt; 2.0 random ~&gt; 3.0"},{"location":"examples/permissions-boundary/#providers","title":"Providers","text":"Name Version aws 5.82.1 random 3.6.3 terraform n/a"},{"location":"examples/permissions-boundary/#modules","title":"Modules","text":"Name Source Version base ../base n/a runners ../../ n/a"},{"location":"examples/permissions-boundary/#resources","title":"Resources","text":"Name Type aws_kms_alias.github resource aws_kms_key.github resource random_id.random resource terraform_remote_state.iam data source"},{"location":"examples/permissions-boundary/#inputs","title":"Inputs","text":"Name Description Type Default Required github_app GitHub for API usages. <pre>object({    id         = string    key_base64 = string  })</pre> n/a yes"},{"location":"examples/permissions-boundary/#outputs","title":"Outputs","text":"Name Description runners n/a webhook n/a"},{"location":"examples/prebuilt/","title":"Ubuntu custom AMI example","text":"<p>This module shows how to create GitHub action runners using a prebuilt AMI for the runners.</p> <ul> <li>Configured to run with org level runners.</li> <li>GitHub runner binary syncer is not deployed.</li> </ul> <p>@@ Usages</p>"},{"location":"examples/prebuilt/#packer-image","title":"Packer Image","text":"<p>You will need to build your image. This example deployment uses the image example in <code>/images/linux-amz2</code>. You must build this image with packer in your AWS account first. Once you have built this you need to provider your owner ID as a variable</p>"},{"location":"examples/prebuilt/#deploy","title":"Deploy","text":"<p>To use your image in the terraform modules you will need to set some values on the module.</p> <p>Assuming you have built the <code>linux-al2023</code> image which has a pre-defined AMI name in the following format <code>github-runner-al2023-x86_64-YYYYMMDDhhmm</code> you can use the following values.</p> <pre><code>module \"runners\" {\n  ...\n  # set the name of the ami to use\n  ami_filter        = { name = [\"github-runner-al2023-x86_64-2023*\"], state = [\"available\"] }\n  # provide the owner id of\n  ami_owners        = [\"&lt;your owner id&gt;\"]\n\n  enable_userdata = false\n  ...\n}\n</code></pre> <p>If your owner is the same as the account you are logging into then you can use <code>aws_caller_identity</code> to retrieve it dynamically.</p> <pre><code>data \"aws_caller_identity\" \"current\" {}\n\nmodule \"runners\" {\n  ...\n  ami_owners       = [data.aws_caller_identity.current.account_id]\n  ...\n}\n</code></pre> <p>You can then deploy the terraform</p> <pre><code>terraform init\nterraform apply\n</code></pre> <p>The module will try to update the GitHub App webhook and secret (only linux/mac). You can receive the webhook details by running:</p> <pre><code>terraform output webhook_secret\n</code></pre>"},{"location":"examples/prebuilt/#requirements","title":"Requirements","text":"Name Version terraform &gt;= 1.3.0 aws ~&gt; 5.27 local ~&gt; 2.0 random ~&gt; 3.0"},{"location":"examples/prebuilt/#providers","title":"Providers","text":"Name Version aws 5.82.1 random 3.6.3"},{"location":"examples/prebuilt/#modules","title":"Modules","text":"Name Source Version base ../base n/a runners ../../ n/a webhook_github_app ../../modules/webhook-github-app n/a"},{"location":"examples/prebuilt/#resources","title":"Resources","text":"Name Type random_id.random resource aws_caller_identity.current data source"},{"location":"examples/prebuilt/#inputs","title":"Inputs","text":"Name Description Type Default Required ami_name_filter AMI name filter for the action runner AMI. By default amazon linux 2 is used. <code>string</code> <code>\"github-runner-al2023-x86_64-*\"</code> no github_app GitHub for API usages. <pre>object({    id         = string    key_base64 = string  })</pre> n/a yes runner_os The EC2 Operating System type to use for action runner instances (linux,windows). <code>string</code> <code>\"linux\"</code> no"},{"location":"examples/prebuilt/#outputs","title":"Outputs","text":"Name Description webhook_endpoint n/a webhook_secret n/a"},{"location":"examples/termination-watcher/","title":"Termination watcher","text":"<p>This module shows how to use the termination watcher stand-alone.</p>"},{"location":"examples/termination-watcher/#usages","title":"Usages","text":"<p>Esnure your have the lambda for the termination locally build. By default the one in the lambdas folder will be used.</p> <p>Build lambda's (requires node and yarn).</p> <pre><code>cd lambdas\nyarn install &amp;&amp; yarn dist\n</code></pre> <p>Next switch to this example directory.</p> <pre><code>terraform init\nterraform apply\n</code></pre> <p>Once a Spot instance is terminated a log line and metric will be updated. Spot instance termination can be simulated using the Amazon Fault Injection Service (FIS). In thw web console you can simply initiate a spot instance failure by navigate in the EC2 console to Spot Requests and choose the action initiate a spot termination event.</p>"},{"location":"examples/termination-watcher/#requirements","title":"Requirements","text":"Name Version terraform &gt;= 1"},{"location":"examples/termination-watcher/#providers","title":"Providers","text":"<p>No providers.</p>"},{"location":"examples/termination-watcher/#modules","title":"Modules","text":"Name Source Version spot_termination_watchter ../../modules/termination-watcher n/a"},{"location":"examples/termination-watcher/#resources","title":"Resources","text":"<p>No resources.</p>"},{"location":"examples/termination-watcher/#inputs","title":"Inputs","text":"<p>No inputs.</p>"},{"location":"examples/termination-watcher/#outputs","title":"Outputs","text":"<p>No outputs.</p>"},{"location":"modules/runners/","title":"Runner module (main)","text":"<p>Note</p> <p>This is the top-level module located in the root of the repository. The directory <code>modules/runners</code> contains an internal Terraform sub-module used by this and the mult-runner module</p> <p>This module creates resources in your AWS infrastructure, and EC2 instances for hosting the self-hosted runners on-demand. IAM permissions are set to a minimal level, and could be further limited by using permission boundaries. Instances permissions are limited to retrieve and delete the registration token, access the instance's own tags, and terminate the instance itself. By nature instances are short-lived, we strongly suggest to use ephemeral runners to ensure a safe build environment for each workflow job execution.</p> <p>Example usages:</p> <ul> <li>Basic example</li> <li>Ephemeral example</li> </ul>"},{"location":"modules/runners/#requirements","title":"Requirements","text":"Name Version terraform &gt;= 1.3.0 aws ~&gt; 5.77 random ~&gt; 3.0"},{"location":"modules/runners/#providers","title":"Providers","text":"Name Version aws ~&gt; 5.77 random ~&gt; 3.0"},{"location":"modules/runners/#modules","title":"Modules","text":"Name Source Version ami_housekeeper ./modules/ami-housekeeper n/a instance_termination_watcher ./modules/termination-watcher n/a runner_binaries ./modules/runner-binaries-syncer n/a runners ./modules/runners n/a ssm ./modules/ssm n/a webhook ./modules/webhook n/a"},{"location":"modules/runners/#resources","title":"Resources","text":"Name Type aws_sqs_queue.queued_builds resource aws_sqs_queue.queued_builds_dlq resource aws_sqs_queue_policy.build_queue_dlq_policy resource aws_sqs_queue_policy.build_queue_policy resource random_string.random resource aws_iam_policy_document.deny_unsecure_transport data source"},{"location":"modules/runners/#inputs","title":"Inputs","text":"Name Description Type Default Required ami_filter Map of lists used to create the AMI filter for the action runner AMI. <code>map(list(string))</code> <pre>{  \"state\": [    \"available\"  ]}</pre> no ami_housekeeper_cleanup_config Configuration for AMI cleanup. <code>amiFilters</code> - Filters to use when searching for AMIs to cleanup. Default filter for images owned by the account and that are available. <code>dryRun</code> - If true, no AMIs will be deregistered. Default false. <code>launchTemplateNames</code> - Launch template names to use when searching for AMIs to cleanup. Default no launch templates. <code>maxItems</code> - The maximum numer of AMI's tha will be queried for cleanup. Default no maximum. <code>minimumDaysOld</code> - Minimum number of days old an AMI must be to be considered for cleanup. Default 30. <code>ssmParameterNames</code> - SSM parameter names to use when searching for AMIs to cleanup. This parameter should be set when using SSM to configure the AMI to use. Default no SSM parameters. <pre>object({    amiFilters = optional(list(object({      Name   = string      Values = list(string)      })),      [{        Name : \"state\",        Values : [\"available\"],        },        {          Name : \"image-type\",          Values : [\"machine\"],      }]    )    dryRun              = optional(bool, false)    launchTemplateNames = optional(list(string))    maxItems            = optional(number)    minimumDaysOld      = optional(number, 30)    ssmParameterNames   = optional(list(string))  })</pre> <code>{}</code> no ami_housekeeper_lambda_s3_key S3 key for syncer lambda function. Required if using S3 bucket to specify lambdas. <code>string</code> <code>null</code> no ami_housekeeper_lambda_s3_object_version S3 object version for syncer lambda function. Useful if S3 versioning is enabled on source bucket. <code>string</code> <code>null</code> no ami_housekeeper_lambda_schedule_expression Scheduler expression for action runner binary syncer. <code>string</code> <code>\"rate(1 day)\"</code> no ami_housekeeper_lambda_timeout Time out of the lambda in seconds. <code>number</code> <code>300</code> no ami_housekeeper_lambda_zip File location of the lambda zip file. <code>string</code> <code>null</code> no ami_id_ssm_parameter_name Externally managed SSM parameter (of data type aws:ec2:image) that contains the AMI ID to launch runner instances from. Overrides ami_filter <code>string</code> <code>null</code> no ami_kms_key_arn Optional CMK Key ARN to be used to launch an instance from a shared encrypted AMI <code>string</code> <code>null</code> no ami_owners The list of owners used to select the AMI of action runner instances. <code>list(string)</code> <pre>[  \"amazon\"]</pre> no associate_public_ipv4_address Associate public IPv4 with the runner. Only tested with IPv4 <code>bool</code> <code>false</code> no aws_partition (optiona) partition in the arn namespace to use if not 'aws' <code>string</code> <code>\"aws\"</code> no aws_region AWS region. <code>string</code> n/a yes block_device_mappings The EC2 instance block device configuration. Takes the following keys: <code>device_name</code>, <code>delete_on_termination</code>, <code>volume_type</code>, <code>volume_size</code>, <code>encrypted</code>, <code>iops</code>, <code>throughput</code>, <code>kms_key_id</code>, <code>snapshot_id</code>. <pre>list(object({    delete_on_termination = optional(bool, true)    device_name           = optional(string, \"/dev/xvda\")    encrypted             = optional(bool, true)    iops                  = optional(number)    kms_key_id            = optional(string)    snapshot_id           = optional(string)    throughput            = optional(number)    volume_size           = number    volume_type           = optional(string, \"gp3\")  }))</pre> <pre>[  {    \"volume_size\": 30  }]</pre> no cloudwatch_config (optional) Replaces the module's default cloudwatch log config. See https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-Agent-Configuration-File-Details.html for details. <code>string</code> <code>null</code> no create_service_linked_role_spot (optional) create the service linked role for spot instances that is required by the scale-up lambda. <code>bool</code> <code>false</code> no delay_webhook_event The number of seconds the event accepted by the webhook is invisible on the queue before the scale up lambda will receive the event. <code>number</code> <code>30</code> no disable_runner_autoupdate Disable the auto update of the github runner agent. Be aware there is a grace period of 30 days, see also the GitHub article <code>bool</code> <code>false</code> no enable_ami_housekeeper Option to disable the lambda to clean up old AMIs. <code>bool</code> <code>false</code> no enable_cloudwatch_agent Enables the cloudwatch agent on the ec2 runner instances. The runner uses a default config that can be overridden via <code>cloudwatch_config</code>. <code>bool</code> <code>true</code> no enable_ephemeral_runners Enable ephemeral runners, runners will only be used once. <code>bool</code> <code>false</code> no enable_jit_config Overwrite the default behavior for JIT configuration. By default JIT configuration is enabled for ephemeral runners and disabled for non-ephemeral runners. In case of GHES check first if the JIT config API is avaialbe. In case you upgradeing from 3.x to 4.x you can set <code>enable_jit_config</code> to <code>false</code> to avoid a breaking change when having your own AMI. <code>bool</code> <code>null</code> no enable_job_queued_check Only scale if the job event received by the scale up lambda is in the queued state. By default enabled for non ephemeral runners and disabled for ephemeral. Set this variable to overwrite the default behavior. <code>bool</code> <code>null</code> no enable_managed_runner_security_group Enables creation of the default managed security group. Unmanaged security groups can be specified via <code>runner_additional_security_group_ids</code>. <code>bool</code> <code>true</code> no enable_organization_runners Register runners to organization, instead of repo level <code>bool</code> <code>false</code> no enable_runner_binaries_syncer Option to disable the lambda to sync GitHub runner distribution, useful when using a pre-build AMI. <code>bool</code> <code>true</code> no enable_runner_detailed_monitoring Should detailed monitoring be enabled for the runner. Set this to true if you want to use detailed monitoring. See https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-cloudwatch-new.html for details. <code>bool</code> <code>false</code> no enable_runner_on_demand_failover_for_errors Enable on-demand failover. For example to fall back to on demand when no spot capacity is available the variable can be set to <code>InsufficientInstanceCapacity</code>. When not defined the default behavior is to retry later. <code>list(string)</code> <code>[]</code> no enable_runner_workflow_job_labels_check_all If set to true all labels in the workflow job must match the GitHub labels (os, architecture and <code>self-hosted</code>). When false if any label matches it will trigger the webhook. <code>bool</code> <code>true</code> no enable_ssm_on_runners Enable to allow access to the runner instances for debugging purposes via SSM. Note that this adds additional permissions to the runner instances. <code>bool</code> <code>false</code> no enable_user_data_debug_logging_runner Option to enable debug logging for user-data, this logs all secrets as well. <code>bool</code> <code>false</code> no enable_userdata Should the userdata script be enabled for the runner. Set this to false if you are using your own prebuilt AMI. <code>bool</code> <code>true</code> no eventbridge Enable the use of EventBridge by the module. By enabling this feature events will be put on the EventBridge by the webhook instead of directly dispatching to queues for scaling. <code>enable</code>: Enable the EventBridge feature. <code>accept_events</code>: List can be used to only allow specific events to be putted on the EventBridge. By default all events, empty list will be be interpreted as all events. <pre>object({    enable        = optional(bool, true)    accept_events = optional(list(string), null)  })</pre> <code>{}</code> no ghes_ssl_verify GitHub Enterprise SSL verification. Set to 'false' when custom certificate (chains) is used for GitHub Enterprise Server (insecure). <code>bool</code> <code>true</code> no ghes_url GitHub Enterprise Server URL. Example: https://github.internal.co - DO NOT SET IF USING PUBLIC GITHUB <code>string</code> <code>null</code> no github_app GitHub app parameters, see your github app. Ensure the key is the base64-encoded <code>.pem</code> file (the output of <code>base64 app.private-key.pem</code>, not the content of <code>private-key.pem</code>). <pre>object({    key_base64     = string    id             = string    webhook_secret = string  })</pre> n/a yes idle_config List of time periods, defined as a cron expression, to keep a minimum amount of runners active instead of scaling down to 0. By defining this list you can ensure that in time periods that match the cron expression within 5 seconds a runner is kept idle. <pre>list(object({    cron             = string    timeZone         = string    idleCount        = number    evictionStrategy = optional(string, \"oldest_first\")  }))</pre> <code>[]</code> no instance_allocation_strategy The allocation strategy for spot instances. AWS recommends using <code>price-capacity-optimized</code> however the AWS default is <code>lowest-price</code>. <code>string</code> <code>\"lowest-price\"</code> no instance_max_spot_price Max price price for spot instances per hour. This variable will be passed to the create fleet as max spot price for the fleet. <code>string</code> <code>null</code> no instance_profile_path The path that will be added to the instance_profile, if not set the environment name will be used. <code>string</code> <code>null</code> no instance_target_capacity_type Default lifecycle used for runner instances, can be either <code>spot</code> or <code>on-demand</code>. <code>string</code> <code>\"spot\"</code> no instance_termination_watcher Configuration for the instance termination watcher. This feature is Beta, changes will not trigger a major release as long in beta.<code>enable</code>: Enable or disable the spot termination watcher.'features': Enable or disable features of the termination watcher.<code>memory_size</code>: Memory size linit in MB of the lambda.<code>s3_key</code>: S3 key for syncer lambda function. Required if using S3 bucket to specify lambdas.<code>s3_object_version</code>: S3 object version for syncer lambda function. Useful if S3 versioning is enabled on source bucket.<code>timeout</code>: Time out of the lambda in seconds.<code>zip</code>: File location of the lambda zip file. <pre>object({    enable = optional(bool, false)    features = optional(object({      enable_spot_termination_handler              = optional(bool, true)      enable_spot_termination_notification_watcher = optional(bool, true)    }), {})    memory_size       = optional(number, null)    s3_key            = optional(string, null)    s3_object_version = optional(string, null)    timeout           = optional(number, null)    zip               = optional(string, null)  })</pre> <code>{}</code> no instance_types List of instance types for the action runner. Defaults are based on runner_os (al2023 for linux and Windows Server Core for win). <code>list(string)</code> <pre>[  \"m5.large\",  \"c5.large\"]</pre> no job_queue_retention_in_seconds The number of seconds the job is held in the queue before it is purged. <code>number</code> <code>86400</code> no job_retry Experimental! Can be removed / changed without trigger a major release.Configure job retries. The configuration enables job retries (for ephemeral runners). After creating the insances a message will be published to a job retry queue. The job retry check lambda is checking after a delay if the job is queued. If not the message will be published again on the scale-up (build queue). Using this feature can impact the reate limit of the GitHub app.<code>enable</code>: Enable or disable the job retry feature.<code>delay_in_seconds</code>: The delay in seconds before the job retry check lambda will check the job status.<code>delay_backoff</code>: The backoff factor for the delay.<code>lambda_memory_size</code>: Memory size limit in MB for the job retry check lambda.<code>lambda_timeout</code>: Time out of the job retry check lambda in seconds.<code>max_attempts</code>: The maximum number of attempts to retry the job. <pre>object({    enable             = optional(bool, false)    delay_in_seconds   = optional(number, 300)    delay_backoff      = optional(number, 2)    lambda_memory_size = optional(number, 256)    lambda_timeout     = optional(number, 30)    max_attempts       = optional(number, 1)  })</pre> <code>{}</code> no key_name Key pair name <code>string</code> <code>null</code> no kms_key_arn Optional CMK Key ARN to be used for Parameter Store. This key must be in the current account. <code>string</code> <code>null</code> no lambda_architecture AWS Lambda architecture. Lambda functions using Graviton processors ('arm64') tend to have better price/performance than 'x86_64' functions. <code>string</code> <code>\"arm64\"</code> no lambda_principals (Optional) add extra principals to the role created for execution of the lambda, e.g. for local testing. <pre>list(object({    type        = string    identifiers = list(string)  }))</pre> <code>[]</code> no lambda_runtime AWS Lambda runtime. <code>string</code> <code>\"nodejs22.x\"</code> no lambda_s3_bucket S3 bucket from which to specify lambda functions. This is an alternative to providing local files directly. <code>string</code> <code>null</code> no lambda_security_group_ids List of security group IDs associated with the Lambda function. <code>list(string)</code> <code>[]</code> no lambda_subnet_ids List of subnets in which the action runners will be launched, the subnets needs to be subnets in the <code>vpc_id</code>. <code>list(string)</code> <code>[]</code> no lambda_tags Map of tags that will be added to all the lambda function resources. Note these are additional tags to the default tags. <code>map(string)</code> <code>{}</code> no log_level Logging level for lambda logging. Valid values are  'silly', 'trace', 'debug', 'info', 'warn', 'error', 'fatal'. <code>string</code> <code>\"info\"</code> no logging_kms_key_id Specifies the kms key id to encrypt the logs with. <code>string</code> <code>null</code> no logging_retention_in_days Specifies the number of days you want to retain log events for the lambda log group. Possible values are: 0, 1, 3, 5, 7, 14, 30, 60, 90, 120, 150, 180, 365, 400, 545, 731, 1827, and 3653. <code>number</code> <code>180</code> no matcher_config_parameter_store_tier The tier of the parameter store for the matcher configuration. Valid values are <code>Standard</code>, and <code>Advanced</code>. <code>string</code> <code>\"Standard\"</code> no metrics Configuration for metrics created by the module, by default disabled to avoid additional costs. When metrics are enable all metrics are created unless explicit configured otherwise. <pre>object({    enable    = optional(bool, false)    namespace = optional(string, \"GitHub Runners\")    metric = optional(object({      enable_github_app_rate_limit    = optional(bool, true)      enable_job_retry                = optional(bool, true)      enable_spot_termination_warning = optional(bool, true)    }), {})  })</pre> <code>{}</code> no minimum_running_time_in_minutes The time an ec2 action runner should be running at minimum before terminated, if not busy. <code>number</code> <code>null</code> no pool_config The configuration for updating the pool. The <code>pool_size</code> to adjust to by the events triggered by the <code>schedule_expression</code>. For example you can configure a cron expression for weekdays to adjust the pool to 10 and another expression for the weekend to adjust the pool to 1. Use <code>schedule_expression_timezone</code> to override the schedule time zone (defaults to UTC). <pre>list(object({    schedule_expression          = string    schedule_expression_timezone = optional(string)    size                         = number  }))</pre> <code>[]</code> no pool_lambda_memory_size Memory size limit for scale-up lambda. <code>number</code> <code>512</code> no pool_lambda_reserved_concurrent_executions Amount of reserved concurrent executions for the scale-up lambda function. A value of 0 disables lambda from being triggered and -1 removes any concurrency limitations. <code>number</code> <code>1</code> no pool_lambda_timeout Time out for the pool lambda in seconds. <code>number</code> <code>60</code> no pool_runner_owner The pool will deploy runners to the GitHub org ID, set this value to the org to which you want the runners deployed. Repo level is not supported. <code>string</code> <code>null</code> no prefix The prefix used for naming resources <code>string</code> <code>\"github-actions\"</code> no queue_encryption Configure how data on queues managed by the modules in ecrypted at REST. Options are encryped via SSE, non encrypted and via KMSS. By default encryptes via SSE is enabled. See for more details the Terraform <code>aws_sqs_queue</code> resource https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/sqs_queue. <pre>object({    kms_data_key_reuse_period_seconds = number    kms_master_key_id                 = string    sqs_managed_sse_enabled           = bool  })</pre> <pre>{  \"kms_data_key_reuse_period_seconds\": null,  \"kms_master_key_id\": null,  \"sqs_managed_sse_enabled\": true}</pre> no redrive_build_queue Set options to attach (optional) a dead letter queue to the build queue, the queue between the webhook and the scale up lambda. You have the following options. 1. Disable by setting <code>enabled</code> to false. 2. Enable by setting <code>enabled</code> to <code>true</code>, <code>maxReceiveCount</code> to a number of max retries. <pre>object({    enabled         = bool    maxReceiveCount = number  })</pre> <pre>{  \"enabled\": false,  \"maxReceiveCount\": null}</pre> no repository_white_list List of github repository full names (owner/repo_name) that will be allowed to use the github app. Leave empty for no filtering. <code>list(string)</code> <code>[]</code> no role_path The path that will be added to role path for created roles, if not set the environment name will be used. <code>string</code> <code>null</code> no role_permissions_boundary Permissions boundary that will be added to the created roles. <code>string</code> <code>null</code> no runner_additional_security_group_ids (optional) List of additional security groups IDs to apply to the runner. <code>list(string)</code> <code>[]</code> no runner_architecture The platform architecture of the runner instance_type. <code>string</code> <code>\"x64\"</code> no runner_as_root Run the action runner under the root user. Variable <code>runner_run_as</code> will be ignored. <code>bool</code> <code>false</code> no runner_binaries_s3_logging_bucket Bucket for action runner distribution bucket access logging. <code>string</code> <code>null</code> no runner_binaries_s3_logging_bucket_prefix Bucket prefix for action runner distribution bucket access logging. <code>string</code> <code>null</code> no runner_binaries_s3_sse_configuration Map containing server-side encryption configuration for runner-binaries S3 bucket. <code>any</code> <pre>{  \"rule\": {    \"apply_server_side_encryption_by_default\": {      \"sse_algorithm\": \"AES256\"    }  }}</pre> no runner_binaries_s3_versioning Status of S3 versioning for runner-binaries S3 bucket. Once set to Enabled the change cannot be reverted via Terraform! <code>string</code> <code>\"Disabled\"</code> no runner_binaries_syncer_lambda_memory_size Memory size limit in MB for binary syncer lambda. <code>number</code> <code>256</code> no runner_binaries_syncer_lambda_timeout Time out of the binaries sync lambda in seconds. <code>number</code> <code>300</code> no runner_binaries_syncer_lambda_zip File location of the binaries sync lambda zip file. <code>string</code> <code>null</code> no runner_boot_time_in_minutes The minimum time for an EC2 runner to boot and register as a runner. <code>number</code> <code>5</code> no runner_credit_specification The credit option for CPU usage of a T instance. Can be unset, \"standard\" or \"unlimited\". <code>string</code> <code>null</code> no runner_disable_default_labels Disable default labels for the runners (os, architecture and <code>self-hosted</code>). If enabled, the runner will only have the extra labels provided in <code>runner_extra_labels</code>. In case you on own start script is used, this configuration parameter needs to be parsed via SSM. <code>bool</code> <code>false</code> no runner_ec2_tags Map of tags that will be added to the launch template instance tag specifications. <code>map(string)</code> <code>{}</code> no runner_egress_rules List of egress rules for the GitHub runner instances. <pre>list(object({    cidr_blocks      = list(string)    ipv6_cidr_blocks = list(string)    prefix_list_ids  = list(string)    from_port        = number    protocol         = string    security_groups  = list(string)    self             = bool    to_port          = number    description      = string  }))</pre> <pre>[  {    \"cidr_blocks\": [      \"0.0.0.0/0\"    ],    \"description\": null,    \"from_port\": 0,    \"ipv6_cidr_blocks\": [      \"::/0\"    ],    \"prefix_list_ids\": null,    \"protocol\": \"-1\",    \"security_groups\": null,    \"self\": null,    \"to_port\": 0  }]</pre> no runner_extra_labels Extra (custom) labels for the runners (GitHub). Separate each label by a comma. Labels checks on the webhook can be enforced by setting <code>enable_workflow_job_labels_check</code>. GitHub read-only labels should not be provided. <code>list(string)</code> <code>[]</code> no runner_group_name Name of the runner group. <code>string</code> <code>\"Default\"</code> no runner_hook_job_completed Script to be ran in the runner environment at the end of every job <code>string</code> <code>\"\"</code> no runner_hook_job_started Script to be ran in the runner environment at the beginning of every job <code>string</code> <code>\"\"</code> no runner_iam_role_managed_policy_arns Attach AWS or customer-managed IAM policies (by ARN) to the runner IAM role <code>list(string)</code> <code>[]</code> no runner_log_files (optional) Replaces the module default cloudwatch log config. See https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-Agent-Configuration-File-Details.html for details. <pre>list(object({    log_group_name   = string    prefix_log_group = bool    file_path        = string    log_stream_name  = string  }))</pre> <code>null</code> no runner_metadata_options Metadata options for the ec2 runner instances. By default, the module uses metadata tags for bootstrapping the runner, only disable <code>instance_metadata_tags</code> when using custom scripts for starting the runner. <code>map(any)</code> <pre>{  \"http_endpoint\": \"enabled\",  \"http_put_response_hop_limit\": 1,  \"http_tokens\": \"required\",  \"instance_metadata_tags\": \"enabled\"}</pre> no runner_name_prefix The prefix used for the GitHub runner name. The prefix will be used in the default start script to prefix the instance name when register the runner in GitHub. The value is availabe via an EC2 tag 'ghr:runner_name_prefix'. <code>string</code> <code>\"\"</code> no runner_os The EC2 Operating System type to use for action runner instances (linux,windows). <code>string</code> <code>\"linux\"</code> no runner_run_as Run the GitHub actions agent as user. <code>string</code> <code>\"ec2-user\"</code> no runners_ebs_optimized Enable EBS optimization for the runner instances. <code>bool</code> <code>false</code> no runners_lambda_s3_key S3 key for runners lambda function. Required if using S3 bucket to specify lambdas. <code>string</code> <code>null</code> no runners_lambda_s3_object_version S3 object version for runners lambda function. Useful if S3 versioning is enabled on source bucket. <code>string</code> <code>null</code> no runners_lambda_zip File location of the lambda zip file for scaling runners. <code>string</code> <code>null</code> no runners_maximum_count The maximum number of runners that will be created. <code>number</code> <code>3</code> no runners_scale_down_lambda_memory_size Memory size limit in MB for scale-down lambda. <code>number</code> <code>512</code> no runners_scale_down_lambda_timeout Time out for the scale down lambda in seconds. <code>number</code> <code>60</code> no runners_scale_up_lambda_memory_size Memory size limit in MB for scale-up lambda. <code>number</code> <code>512</code> no runners_scale_up_lambda_timeout Time out for the scale up lambda in seconds. <code>number</code> <code>30</code> no runners_ssm_housekeeper Configuration for the SSM housekeeper lambda. This lambda deletes token / JIT config from SSM. <code>schedule_expression</code>: is used to configure the schedule for the lambda. <code>enabled</code>: enable or disable the lambda trigger via the EventBridge. <code>lambda_memory_size</code>: lambda memery size limit. <code>lambda_timeout</code>: timeout for the lambda in seconds. <code>config</code>: configuration for the lambda function. Token path will be read by default from the module. <pre>object({    schedule_expression = optional(string, \"rate(1 day)\")    enabled             = optional(bool, true)    lambda_memory_size  = optional(number, 512)    lambda_timeout      = optional(number, 60)    config = object({      tokenPath      = optional(string)      minimumDaysOld = optional(number, 1)      dryRun         = optional(bool, false)    })  })</pre> <pre>{  \"config\": {}}</pre> no scale_down_schedule_expression Scheduler expression to check every x for scale down. <code>string</code> <code>\"cron(*/5 * * * ? *)\"</code> no scale_up_reserved_concurrent_executions Amount of reserved concurrent executions for the scale-up lambda function. A value of 0 disables lambda from being triggered and -1 removes any concurrency limitations. <code>number</code> <code>1</code> no ssm_paths The root path used in SSM to store configuration and secrets. <pre>object({    root       = optional(string, \"github-action-runners\")    app        = optional(string, \"app\")    runners    = optional(string, \"runners\")    webhook    = optional(string, \"webhook\")    use_prefix = optional(bool, true)  })</pre> <code>{}</code> no state_event_rule_binaries_syncer Option to disable EventBridge Lambda trigger for the binary syncer, useful to stop automatic updates of binary distribution <code>string</code> <code>\"ENABLED\"</code> no subnet_ids List of subnets in which the action runner instances will be launched. The subnets need to exist in the configured VPC (<code>vpc_id</code>), and must reside in different availability zones (see https://github.com/github-aws-runners/terraform-aws-github-runner/issues/2904) <code>list(string)</code> n/a yes syncer_lambda_s3_key S3 key for syncer lambda function. Required if using an S3 bucket to specify lambdas. <code>string</code> <code>null</code> no syncer_lambda_s3_object_version S3 object version for syncer lambda function. Useful if S3 versioning is enabled on source bucket. <code>string</code> <code>null</code> no tags Map of tags that will be added to created resources. By default resources will be tagged with name and environment. <code>map(string)</code> <code>{}</code> no tracing_config Configuration for lambda tracing. <pre>object({    mode                  = optional(string, null)    capture_http_requests = optional(bool, false)    capture_error         = optional(bool, false)  })</pre> <code>{}</code> no userdata_content Alternative user-data content, replacing the templated one. By providing your own user_data you have to take care of installing all required software, including the action runner and registering the runner.  Be-aware configuration paramaters in SSM as well as tags are treated as internals. Changes will not trigger a breaking release. <code>string</code> <code>null</code> no userdata_post_install Script to be ran after the GitHub Actions runner is installed on the EC2 instances <code>string</code> <code>\"\"</code> no userdata_pre_install Script to be ran before the GitHub Actions runner is installed on the EC2 instances <code>string</code> <code>\"\"</code> no userdata_template Alternative user-data template file path, replacing the default template. By providing your own user_data you have to take care of installing all required software, including the action runner. Variables userdata_pre/post_install are ignored. <code>string</code> <code>null</code> no vpc_id The VPC for security groups of the action runners. <code>string</code> n/a yes webhook_lambda_apigateway_access_log_settings Access log settings for webhook API gateway. <pre>object({    destination_arn = string    format          = string  })</pre> <code>null</code> no webhook_lambda_memory_size Memory size limit in MB for webhook lambda in. <code>number</code> <code>256</code> no webhook_lambda_s3_key S3 key for webhook lambda function. Required if using S3 bucket to specify lambdas. <code>string</code> <code>null</code> no webhook_lambda_s3_object_version S3 object version for webhook lambda function. Useful if S3 versioning is enabled on source bucket. <code>string</code> <code>null</code> no webhook_lambda_timeout Time out of the webhook lambda in seconds. <code>number</code> <code>10</code> no webhook_lambda_zip File location of the webhook lambda zip file. <code>string</code> <code>null</code> no"},{"location":"modules/runners/#outputs","title":"Outputs","text":"Name Description binaries_syncer n/a instance_termination_handler n/a instance_termination_watcher n/a queues SQS queues. runners n/a ssm_parameters n/a webhook n/a"},{"location":"modules/internal/runner-binaries-syncer/","title":"Module - Runner binaries syncer","text":"<p>This module is treated as internal module, breaking changes will not trigger a major release bump.</p> <p>This module creates a lambda that will sync GitHub action binary to a S3 bucket, the lambda will be triggered via a CloudWatch event. The distribution is cached to avoid the latency of downloading the distribution during the setup. After deployment the lambda will be triggered via an S3 object created at deployment time.</p>"},{"location":"modules/internal/runner-binaries-syncer/#lambda-function","title":"Lambda Function","text":"<p>The Lambda function is written in TypeScript and requires Node 12.x and yarn. Sources are located in [./lambdas/runners-binaries-syncer].</p>"},{"location":"modules/internal/runner-binaries-syncer/#install","title":"Install","text":"<pre><code>cd lambdas/runners\nyarn install\n</code></pre>"},{"location":"modules/internal/runner-binaries-syncer/#test","title":"Test","text":"<p>Test are implemented with Jest, calls to AWS and GitHub are mocked.</p> <pre><code>yarn run test\n</code></pre>"},{"location":"modules/internal/runner-binaries-syncer/#package","title":"Package","text":"<p>To compile all TypeScript/JavaScript sources in a single file ncc is used.</p> <pre><code>yarn run dist\n</code></pre>"},{"location":"modules/internal/runner-binaries-syncer/#requirements","title":"Requirements","text":"Name Version terraform &gt;= 1.3.0 aws ~&gt; 5.27"},{"location":"modules/internal/runner-binaries-syncer/#providers","title":"Providers","text":"Name Version aws ~&gt; 5.27"},{"location":"modules/internal/runner-binaries-syncer/#modules","title":"Modules","text":"<p>No modules.</p>"},{"location":"modules/internal/runner-binaries-syncer/#resources","title":"Resources","text":"Name Type aws_cloudwatch_event_rule.syncer resource aws_cloudwatch_event_target.syncer resource aws_cloudwatch_log_group.syncer resource aws_iam_role.syncer_lambda resource aws_iam_role_policy.lambda_kms resource aws_iam_role_policy.lambda_logging resource aws_iam_role_policy.syncer resource aws_iam_role_policy.syncer_lambda_xray resource aws_iam_role_policy_attachment.syncer_vpc_execution_role resource aws_lambda_function.syncer resource aws_lambda_permission.on_deploy resource aws_lambda_permission.syncer resource aws_s3_bucket.action_dist resource aws_s3_bucket_lifecycle_configuration.bucket_config resource aws_s3_bucket_logging.action_dist_logging resource aws_s3_bucket_notification.on_deploy resource aws_s3_bucket_ownership_controls.this resource aws_s3_bucket_policy.action_dist_bucket_policy resource aws_s3_bucket_public_access_block.action_dist resource aws_s3_bucket_server_side_encryption_configuration.action_dist resource aws_s3_bucket_versioning.action_dist resource aws_s3_object.trigger resource aws_caller_identity.current data source aws_iam_policy_document.action_dist_bucket_policy data source aws_iam_policy_document.lambda_assume_role_policy data source aws_iam_policy_document.lambda_xray data source"},{"location":"modules/internal/runner-binaries-syncer/#inputs","title":"Inputs","text":"Name Description Type Default Required aws_partition (optional) partition for the base arn if not 'aws' <code>string</code> <code>\"aws\"</code> no distribution_bucket_name Bucket for storing the action runner distribution. <code>string</code> n/a yes lambda_architecture AWS Lambda architecture. Lambda functions using Graviton processors ('arm64') tend to have better price/performance than 'x86_64' functions. <code>string</code> <code>\"arm64\"</code> no lambda_memory_size Memory size of the lambda. <code>number</code> <code>256</code> no lambda_principals (Optional) add extra principals to the role created for execution of the lambda, e.g. for local testing. <pre>list(object({    type        = string    identifiers = list(string)  }))</pre> <code>[]</code> no lambda_runtime AWS Lambda runtime. <code>string</code> <code>\"nodejs22.x\"</code> no lambda_s3_bucket S3 bucket from which to specify lambda functions. This is an alternative to providing local files directly. <code>string</code> <code>null</code> no lambda_schedule_expression Scheduler expression for action runner binary syncer. <code>string</code> <code>\"cron(27 * * * ? *)\"</code> no lambda_security_group_ids List of security group IDs associated with the Lambda function. <code>list(string)</code> <code>[]</code> no lambda_subnet_ids List of subnets in which the action runners will be launched, the subnets needs to be subnets in the <code>vpc_id</code>. <code>list(string)</code> <code>[]</code> no lambda_tags Map of tags that will be added to all the lambda function resources. Note these are additional tags to the default tags. <code>map(string)</code> <code>{}</code> no lambda_timeout Time out of the lambda in seconds. <code>number</code> <code>300</code> no lambda_zip File location of the lambda zip file. <code>string</code> <code>null</code> no log_level Logging level for lambda logging. Valid values are  'silly', 'trace', 'debug', 'info', 'warn', 'error', 'fatal'. <code>string</code> <code>\"info\"</code> no logging_kms_key_id Specifies the kms key id to encrypt the logs with <code>string</code> <code>null</code> no logging_retention_in_days Specifies the number of days you want to retain log events for the lambda log group. Possible values are: 0, 1, 3, 5, 7, 14, 30, 60, 90, 120, 150, 180, 365, 400, 545, 731, 1827, and 3653. <code>number</code> <code>180</code> no prefix The prefix used for naming resources <code>string</code> <code>\"github-actions\"</code> no role_path The path that will be added to the role, if not set the environment name will be used. <code>string</code> <code>null</code> no role_permissions_boundary Permissions boundary that will be added to the created role for the lambda. <code>string</code> <code>null</code> no runner_architecture The platform architecture of the runner instance_type. <code>string</code> <code>\"x64\"</code> no runner_os The EC2 Operating System type to use for action runner instances (linux,windows). <code>string</code> <code>\"linux\"</code> no s3_logging_bucket Bucket for action runner distribution bucket access logging. <code>string</code> <code>null</code> no s3_logging_bucket_prefix Bucket prefix for action runner distribution bucket access logging. <code>string</code> <code>null</code> no s3_versioning Status of S3 versioning for runner-binaries S3 bucket. <code>string</code> <code>\"Disabled\"</code> no server_side_encryption_configuration Map containing server-side encryption configuration for runner-binaries S3 bucket. <code>any</code> <pre>{  \"rule\": {    \"apply_server_side_encryption_by_default\": {      \"sse_algorithm\": \"AES256\"    }  }}</pre> no state_event_rule_binaries_syncer Option to disable EventBridge Lambda trigger for the binary syncer, useful to stop automatic updates of binary distribution <code>string</code> <code>\"ENABLED\"</code> no syncer_lambda_s3_key S3 key for syncer lambda function. Required if using S3 bucket to specify lambdas. <code>string</code> <code>null</code> no syncer_lambda_s3_object_version S3 object version for syncer lambda function. Useful if S3 versioning is enabled on source bucket. <code>string</code> <code>null</code> no tags Map of tags that will be added to created resources. By default resources will be tagged with name and environment. <code>map(string)</code> <code>{}</code> no tracing_config Configuration for lambda tracing. <pre>object({    mode                  = optional(string, null)    capture_http_requests = optional(bool, false)    capture_error         = optional(bool, false)  })</pre> <code>{}</code> no"},{"location":"modules/internal/runner-binaries-syncer/#outputs","title":"Outputs","text":"Name Description bucket n/a lambda n/a lambda_log_group n/a lambda_role n/a runner_distribution_object_key n/a"},{"location":"modules/internal/runners/","title":"Module - Scale runners","text":"<p>This module is treated as internal module, breaking changes will not trigger a major release bump.</p> <p>This module creates resources required to run the GitHub action runner on AWS EC2 spot instances. The life cycle of the runners on AWS is managed by two lambda functions. One function will handle scaling up, the other scaling down.</p>"},{"location":"modules/internal/runners/#overview","title":"Overview","text":""},{"location":"modules/internal/runners/#action-runners-on-ec2","title":"Action runners on EC2","text":"<p>The action runners are created via a launch template; in the launch template only the subnet needs to be provided. During launch the installation is handled via a user data script. The configuration is fetched from SSM parameter store.</p>"},{"location":"modules/internal/runners/#lambda-scale-up","title":"Lambda scale up","text":"<p>The scale up lambda is triggered by events on a SQS queue. Events on this queue are delayed, which will give the workflow some time to start running on available runners. For each event the lambda will check if the workflow is still queued and no other limits are reached. In that case the lambda will create a new EC2 instance. The lambda only needs to know which launch template to use and which subnets are available. From the available subnets a random one will be chosen. Once the instance is created the event is assumed as handled, and we assume the workflow wil start at some moment once the created instance is ready.</p>"},{"location":"modules/internal/runners/#lambda-scale-down","title":"Lambda scale down","text":"<p>The scale down lambda is triggered via a CloudWatch event. The event is triggered by a cron expression defined in the variable <code>scale_down_schedule_expression</code> (https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/ScheduledEvents.html). For scaling down GitHub does not provide a good API yet, therefore we run the scaling down based on this event every x minutes. Each time the lambda is triggered it tries to remove all runners older than x minutes (configurable) managed in this deployment. In case the runner can be removed from GitHub, which means it is not executing a workflow, the lambda will terminate the EC2 instance.</p>"},{"location":"modules/internal/runners/#lambda-function","title":"Lambda Function","text":"<p>The Lambda function is written in TypeScript and requires Node 12.x and yarn. Sources are located in [./lambdas/runners]. Two lambda functions share the same sources, there is one entry point for <code>scaleDown</code> and another one for <code>scaleUp</code>.</p>"},{"location":"modules/internal/runners/#install","title":"Install","text":"<pre><code>cd lambdas/runners\nyarn install\n</code></pre>"},{"location":"modules/internal/runners/#test","title":"Test","text":"<p>Test are implemented with Jest, calls to AWS and GitHub are mocked.</p> <pre><code>yarn run test\n</code></pre>"},{"location":"modules/internal/runners/#package","title":"Package","text":"<p>To compile all TypeScript/JavaScript sources in a single file ncc is used.</p> <pre><code>yarn run dist\n</code></pre>"},{"location":"modules/internal/runners/#requirements","title":"Requirements","text":"Name Version terraform &gt;= 1.3.0 aws ~&gt; 5.27"},{"location":"modules/internal/runners/#providers","title":"Providers","text":"Name Version aws ~&gt; 5.27"},{"location":"modules/internal/runners/#modules","title":"Modules","text":"Name Source Version job_retry ./job-retry n/a pool ./pool n/a"},{"location":"modules/internal/runners/#resources","title":"Resources","text":"Name Type aws_cloudwatch_event_rule.scale_down resource aws_cloudwatch_event_rule.ssm_housekeeper resource aws_cloudwatch_event_target.scale_down resource aws_cloudwatch_event_target.ssm_housekeeper resource aws_cloudwatch_log_group.gh_runners resource aws_cloudwatch_log_group.scale_down resource aws_cloudwatch_log_group.scale_up resource aws_cloudwatch_log_group.ssm_housekeeper resource aws_iam_instance_profile.runner resource aws_iam_policy.ami_id_ssm_parameter_read resource aws_iam_role.runner resource aws_iam_role.scale_down resource aws_iam_role.scale_up resource aws_iam_role.ssm_housekeeper resource aws_iam_role_policy.cloudwatch resource aws_iam_role_policy.describe_tags resource aws_iam_role_policy.dist_bucket resource aws_iam_role_policy.ec2 resource aws_iam_role_policy.job_retry_sqs_publish resource aws_iam_role_policy.runner_session_manager_aws_managed resource aws_iam_role_policy.scale_down resource aws_iam_role_policy.scale_down_logging resource aws_iam_role_policy.scale_down_xray resource aws_iam_role_policy.scale_up resource aws_iam_role_policy.scale_up_logging resource aws_iam_role_policy.scale_up_xray resource aws_iam_role_policy.service_linked_role resource aws_iam_role_policy.ssm_housekeeper resource aws_iam_role_policy.ssm_housekeeper_logging resource aws_iam_role_policy.ssm_housekeeper_xray resource aws_iam_role_policy.ssm_parameters resource aws_iam_role_policy_attachment.ami_id_ssm_parameter_read resource aws_iam_role_policy_attachment.managed_policies resource aws_iam_role_policy_attachment.scale_down_vpc_execution_role resource aws_iam_role_policy_attachment.scale_up_vpc_execution_role resource aws_iam_role_policy_attachment.ssm_housekeeper_vpc_execution_role resource aws_iam_role_policy_attachment.xray_tracing resource aws_lambda_event_source_mapping.scale_up resource aws_lambda_function.scale_down resource aws_lambda_function.scale_up resource aws_lambda_function.ssm_housekeeper resource aws_lambda_permission.scale_down resource aws_lambda_permission.scale_runners_lambda resource aws_lambda_permission.ssm_housekeeper resource aws_launch_template.runner resource aws_security_group.runner_sg resource aws_ssm_parameter.cloudwatch_agent_config_runner resource aws_ssm_parameter.disable_default_labels resource aws_ssm_parameter.jit_config_enabled resource aws_ssm_parameter.runner_agent_mode resource aws_ssm_parameter.runner_config_run_as resource aws_ssm_parameter.runner_enable_cloudwatch resource aws_ssm_parameter.token_path resource aws_ami.runner data source aws_caller_identity.current data source aws_iam_policy_document.lambda_assume_role_policy data source aws_iam_policy_document.lambda_xray data source"},{"location":"modules/internal/runners/#inputs","title":"Inputs","text":"Name Description Type Default Required ami_filter Map of lists used to create the AMI filter for the action runner AMI. <code>map(list(string))</code> <pre>{  \"state\": [    \"available\"  ]}</pre> no ami_id_ssm_parameter_name Externally managed SSM parameter (of data type aws:ec2:image) that contains the AMI ID to launch runner instances from. Overrides ami_filter <code>string</code> <code>null</code> no ami_kms_key_arn Optional CMK Key ARN to be used to launch an instance from a shared encrypted AMI <code>string</code> <code>null</code> no ami_owners The list of owners used to select the AMI of action runner instances. <code>list(string)</code> <pre>[  \"amazon\"]</pre> no associate_public_ipv4_address Associate public IPv4 with the runner. Only tested with IPv4 <code>bool</code> <code>false</code> no aws_partition (optional) partition for the base arn if not 'aws' <code>string</code> <code>\"aws\"</code> no aws_region AWS region. <code>string</code> n/a yes block_device_mappings The EC2 instance block device configuration. Takes the following keys: <code>device_name</code>, <code>delete_on_termination</code>, <code>volume_type</code>, <code>volume_size</code>, <code>encrypted</code>, <code>iops</code>, <code>throughput</code>, <code>kms_key_id</code>, <code>snapshot_id</code>. <pre>list(object({    delete_on_termination = optional(bool, true)    device_name           = optional(string, \"/dev/xvda\")    encrypted             = optional(bool, true)    iops                  = optional(number)    kms_key_id            = optional(string)    snapshot_id           = optional(string)    throughput            = optional(number)    volume_size           = number    volume_type           = optional(string, \"gp3\")  }))</pre> <pre>[  {    \"volume_size\": 30  }]</pre> no cloudwatch_config (optional) Replaces the module default cloudwatch log config. See https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-Agent-Configuration-File-Details.html for details. <code>string</code> <code>null</code> no create_service_linked_role_spot (optional) create the service linked role for spot instances that is required by the scale-up lambda. <code>bool</code> <code>false</code> no credit_specification The credit option for CPU usage of a T instance. Can be unset, \"standard\" or \"unlimited\". <code>string</code> <code>null</code> no disable_runner_autoupdate Disable the auto update of the github runner agent. Be aware there is a grace period of 30 days, see also the GitHub article <code>bool</code> <code>false</code> no ebs_optimized The EC2 EBS optimized configuration. <code>bool</code> <code>false</code> no egress_rules List of egress rules for the GitHub runner instances. <pre>list(object({    cidr_blocks      = list(string)    ipv6_cidr_blocks = list(string)    prefix_list_ids  = list(string)    from_port        = number    protocol         = string    security_groups  = list(string)    self             = bool    to_port          = number    description      = string  }))</pre> <pre>[  {    \"cidr_blocks\": [      \"0.0.0.0/0\"    ],    \"description\": null,    \"from_port\": 0,    \"ipv6_cidr_blocks\": [      \"::/0\"    ],    \"prefix_list_ids\": null,    \"protocol\": \"-1\",    \"security_groups\": null,    \"self\": null,    \"to_port\": 0  }]</pre> no enable_cloudwatch_agent Enabling the cloudwatch agent on the ec2 runner instances, the runner contains default config. Configuration can be overridden via <code>cloudwatch_config</code>. <code>bool</code> <code>true</code> no enable_ephemeral_runners Enable ephemeral runners, runners will only be used once. <code>bool</code> <code>false</code> no enable_jit_config Overwrite the default behavior for JIT configuration. By default JIT configuration is enabled for ephemeral runners and disabled for non-ephemeral runners. In case of GHES check first if the JIT config API is avaialbe. In case you upgradeing from 3.x to 4.x you can set <code>enable_jit_config</code> to <code>false</code> to avoid a breaking change when having your own AMI. <code>bool</code> <code>null</code> no enable_job_queued_check Only scale if the job event received by the scale up lambda is is in the state queued. By default enabled for non ephemeral runners and disabled for ephemeral. Set this variable to overwrite the default behavior. <code>bool</code> <code>null</code> no enable_managed_runner_security_group Enabling the default managed security group creation. Unmanaged security groups can be specified via <code>runner_additional_security_group_ids</code>. <code>bool</code> <code>true</code> no enable_on_demand_failover_for_errors Enable on-demand failover. For example to fall back to on demand when no spot capacity is available the variable can be set to <code>InsufficientInstanceCapacity</code>. When not defined the default behavior is to retry later. <code>list(string)</code> <code>[]</code> no enable_organization_runners Register runners to organization, instead of repo level <code>bool</code> n/a yes enable_runner_binaries_syncer Option to disable the lambda to sync GitHub runner distribution, useful when using a pre-build AMI. <code>bool</code> <code>true</code> no enable_runner_detailed_monitoring Enable detailed monitoring for runners <code>bool</code> <code>false</code> no enable_ssm_on_runners Enable to allow access to the runner instances for debugging purposes via SSM. Note that this adds additional permissions to the runner instances. <code>bool</code> n/a yes enable_user_data_debug_logging Option to enable debug logging for user-data, this logs all secrets as well. <code>bool</code> <code>false</code> no enable_userdata Should the userdata script be enabled for the runner. Set this to false if you are using your own prebuilt AMI <code>bool</code> <code>true</code> no ghes_ssl_verify GitHub Enterprise SSL verification. Set to 'false' when custom certificate (chains) is used for GitHub Enterprise Server (insecure). <code>bool</code> <code>true</code> no ghes_url GitHub Enterprise Server URL. DO NOT SET IF USING PUBLIC GITHUB <code>string</code> <code>null</code> no github_app_parameters Parameter Store for GitHub App Parameters. <pre>object({    key_base64 = map(string)    id         = map(string)  })</pre> n/a yes idle_config List of time period that can be defined as cron expression to keep a minimum amount of runners active instead of scaling down to 0. By defining this list you can ensure that in time periods that match the cron expression within 5 seconds a runner is kept idle. <pre>list(object({    cron             = string    timeZone         = string    idleCount        = number    evictionStrategy = optional(string, \"oldest_first\")  }))</pre> <code>[]</code> no instance_allocation_strategy The allocation strategy for spot instances. AWS recommends to use <code>capacity-optimized</code> however the AWS default is <code>lowest-price</code>. <code>string</code> <code>\"lowest-price\"</code> no instance_max_spot_price Max price price for spot intances per hour. This variable will be passed to the create fleet as max spot price for the fleet. <code>string</code> <code>null</code> no instance_profile_path The path that will be added to the instance_profile, if not set the prefix will be used. <code>string</code> <code>null</code> no instance_target_capacity_type Default lifecyle used runner instances, can be either <code>spot</code> or <code>on-demand</code>. <code>string</code> <code>\"spot\"</code> no instance_types List of instance types for the action runner. Defaults are based on runner_os (al2023 for linux and Windows Server Core for win). <code>list(string)</code> <code>null</code> no job_retry Configure job retries. The configuration enables job retries (for ephemeral runners). After creating the insances a message will be published to a job retry queue. The job retry check lambda is checking after a delay if the job is queued. If not the message will be published again on the scale-up (build queue). Using this feature can impact the reate limit of the GitHub app.<code>enable</code>: Enable or disable the job retry feature.<code>delay_in_seconds</code>: The delay in seconds before the job retry check lambda will check the job status.<code>delay_backoff</code>: The backoff factor for the delay.<code>lambda_memory_size</code>: Memory size limit in MB for the job retry check lambda.'lambda_reserved_concurrent_executions': Amount of reserved concurrent executions for the job retry check lambda function. A value of 0 disables lambda from being triggered and -1 removes any concurrency limitations.<code>lambda_timeout</code>: Time out of the job retry check lambda in seconds.<code>max_attempts</code>: The maximum number of attempts to retry the job. <pre>object({    enable                                = optional(bool, false)    delay_in_seconds                      = optional(number, 300)    delay_backoff                         = optional(number, 2)    lambda_memory_size                    = optional(number, 256)    lambda_reserved_concurrent_executions = optional(number, 1)    lambda_timeout = optional(number, 30)    max_attempts = optional(number, 1)  })</pre> <code>{}</code> no key_name Key pair name <code>string</code> <code>null</code> no kms_key_arn Optional CMK Key ARN to be used for Parameter Store. <code>string</code> <code>null</code> no lambda_architecture AWS Lambda architecture. Lambda functions using Graviton processors ('arm64') tend to have better price/performance than 'x86_64' functions. <code>string</code> <code>\"arm64\"</code> no lambda_runtime AWS Lambda runtime. <code>string</code> <code>\"nodejs22.x\"</code> no lambda_s3_bucket S3 bucket from which to specify lambda functions. This is an alternative to providing local files directly. <code>string</code> <code>null</code> no lambda_scale_down_memory_size Memory size limit in MB for scale down lambda. <code>number</code> <code>512</code> no lambda_scale_up_memory_size Memory size limit in MB for scale-up lambda. <code>number</code> <code>512</code> no lambda_security_group_ids List of security group IDs associated with the Lambda function. <code>list(string)</code> <code>[]</code> no lambda_subnet_ids List of subnets in which the lambda will be launched, the subnets needs to be subnets in the <code>vpc_id</code>. <code>list(string)</code> <code>[]</code> no lambda_tags Map of tags that will be added to all the lambda function resources. Note these are additional tags to the default tags. <code>map(string)</code> <code>{}</code> no lambda_timeout_scale_down Time out for the scale down lambda in seconds. <code>number</code> <code>60</code> no lambda_timeout_scale_up Time out for the scale up lambda in seconds. <code>number</code> <code>60</code> no lambda_zip File location of the lambda zip file. <code>string</code> <code>null</code> no log_level Logging level for lambda logging. Valid values are  'silly', 'trace', 'debug', 'info', 'warn', 'error', 'fatal'. <code>string</code> <code>\"info\"</code> no logging_kms_key_id Specifies the kms key id to encrypt the logs with <code>string</code> <code>null</code> no logging_retention_in_days Specifies the number of days you want to retain log events for the lambda log group. Possible values are: 0, 1, 3, 5, 7, 14, 30, 60, 90, 120, 150, 180, 365, 400, 545, 731, 1827, and 3653. <code>number</code> <code>180</code> no metadata_options Metadata options for the ec2 runner instances. By default, the module uses metadata tags for bootstrapping the runner, only disable <code>instance_metadata_tags</code> when using custom scripts for starting the runner. <code>map(any)</code> <pre>{  \"http_endpoint\": \"enabled\",  \"http_put_response_hop_limit\": 1,  \"http_tokens\": \"required\",  \"instance_metadata_tags\": \"enabled\"}</pre> no metrics Configuration for metrics created by the module, by default metrics are disabled to avoid additional costs. When metrics are enable all metrics are created unless explicit configured otherwise. <pre>object({    enable    = optional(bool, false)    namespace = optional(string, \"GitHub Runners\")    metric = optional(object({      enable_github_app_rate_limit    = optional(bool, true)      enable_job_retry                = optional(bool, true)      enable_spot_termination_warning = optional(bool, true)    }), {})  })</pre> <code>{}</code> no minimum_running_time_in_minutes The time an ec2 action runner should be running at minimum before terminated if non busy. If not set the default is calculated based on the OS. <code>number</code> <code>null</code> no overrides This map provides the possibility to override some defaults. The following attributes are supported: <code>name_sg</code> overrides the <code>Name</code> tag for all security groups created by this module. <code>name_runner_agent_instance</code> overrides the <code>Name</code> tag for the ec2 instance defined in the auto launch configuration. <code>name_docker_machine_runners</code> overrides the <code>Name</code> tag spot instances created by the runner agent. <code>map(string)</code> <pre>{  \"name_runner\": \"\",  \"name_sg\": \"\"}</pre> no pool_config The configuration for updating the pool. The <code>pool_size</code> to adjust to by the events triggered by the <code>schedule_expression</code>. For example you can configure a cron expression for week days to adjust the pool to 10 and another expression for the weekend to adjust the pool to 1. Use <code>schedule_expression_timezone</code> to override the schedule time zone (defaults to UTC). <pre>list(object({    schedule_expression          = string    schedule_expression_timezone = optional(string)    size                         = number  }))</pre> <code>[]</code> no pool_lambda_memory_size Lambda Memory size limit in MB for pool lambda <code>number</code> <code>512</code> no pool_lambda_reserved_concurrent_executions Amount of reserved concurrent executions for the scale-up lambda function. A value of 0 disables lambda from being triggered and -1 removes any concurrency limitations. <code>number</code> <code>1</code> no pool_lambda_timeout Time out for the pool lambda in seconds. <code>number</code> <code>60</code> no pool_runner_owner The pool will deploy runners to the GitHub org ID, set this value to the org to which you want the runners deployed. Repo level is not supported. <code>string</code> <code>null</code> no prefix The prefix used for naming resources <code>string</code> <code>\"github-actions\"</code> no role_path The path that will be added to the role; if not set, the prefix will be used. <code>string</code> <code>null</code> no role_permissions_boundary Permissions boundary that will be added to the created role for the lambda. <code>string</code> <code>null</code> no runner_additional_security_group_ids (optional) List of additional security groups IDs to apply to the runner <code>list(string)</code> <code>[]</code> no runner_architecture The platform architecture of the runner instance_type. <code>string</code> <code>\"x64\"</code> no runner_as_root Run the action runner under the root user. Variable <code>runner_run_as</code> will be ignored. <code>bool</code> <code>false</code> no runner_boot_time_in_minutes The minimum time for an EC2 runner to boot and register as a runner. <code>number</code> <code>5</code> no runner_disable_default_labels Disable default labels for the runners (os, architecture and <code>self-hosted</code>). If enabled, the runner will only have the extra labels provided in <code>runner_extra_labels</code>. <code>bool</code> <code>false</code> no runner_ec2_tags Map of tags that will be added to the launch template instance tag specifications. <code>map(string)</code> <code>{}</code> no runner_group_name Name of the runner group. <code>string</code> <code>\"Default\"</code> no runner_hook_job_completed Script to be ran in the runner environment at the end of every job <code>string</code> <code>\"\"</code> no runner_hook_job_started Script to be ran in the runner environment at the beginning of every job <code>string</code> <code>\"\"</code> no runner_iam_role_managed_policy_arns Attach AWS or customer-managed IAM policies (by ARN) to the runner IAM role <code>list(string)</code> <code>[]</code> no runner_labels All the labels for the runners (GitHub) including the default one's(e.g: self-hosted, linux, x64, label1, label2). Separate each label by a comma <code>list(string)</code> n/a yes runner_log_files (optional) List of logfiles to send to CloudWatch, will only be used if <code>enable_cloudwatch_agent</code> is set to true. Object description: <code>log_group_name</code>: Name of the log group, <code>prefix_log_group</code>: If true, the log group name will be prefixed with <code>/github-self-hosted-runners/&lt;var.prefix&gt;</code>, <code>file_path</code>: path to the log file, <code>log_stream_name</code>: name of the log stream. <pre>list(object({    log_group_name   = string    prefix_log_group = bool    file_path        = string    log_stream_name  = string  }))</pre> <code>null</code> no runner_name_prefix The prefix used for the GitHub runner name. The prefix will be used in the default start script to prefix the instance name when register the runner in GitHub. The value is availabe via an EC2 tag 'ghr:runner_name_prefix'. <code>string</code> <code>\"\"</code> no runner_os The EC2 Operating System type to use for action runner instances (linux,windows). <code>string</code> <code>\"linux\"</code> no runner_run_as Run the GitHub actions agent as user. <code>string</code> <code>\"ec2-user\"</code> no runners_lambda_s3_key S3 key for runners lambda function. Required if using S3 bucket to specify lambdas. <code>string</code> <code>null</code> no runners_lambda_s3_object_version S3 object version for runners lambda function. Useful if S3 versioning is enabled on source bucket. <code>string</code> <code>null</code> no runners_maximum_count The maximum number of runners that will be created. Setting the variable to <code>-1</code> desiables the maximum check. <code>number</code> <code>3</code> no s3_runner_binaries Bucket details for cached GitHub binary. <pre>object({    arn = string    id  = string    key = string  })</pre> n/a yes scale_down_schedule_expression Scheduler expression to check every x for scale down. <code>string</code> <code>\"cron(*/5 * * * ? *)\"</code> no scale_up_reserved_concurrent_executions Amount of reserved concurrent executions for the scale-up lambda function. A value of 0 disables lambda from being triggered and -1 removes any concurrency limitations. <code>number</code> <code>1</code> no sqs_build_queue SQS queue to consume accepted build events. <pre>object({    arn = string    url = string  })</pre> n/a yes ssm_housekeeper Configuration for the SSM housekeeper lambda. This lambda deletes token / JIT config from SSM. <code>schedule_expression</code>: is used to configure the schedule for the lambda. <code>state</code>: state of the cloudwatch event rule. Valid values are <code>DISABLED</code>, <code>ENABLED</code>, and <code>ENABLED_WITH_ALL_CLOUDTRAIL_MANAGEMENT_EVENTS</code>. <code>lambda_memory_size</code>: lambda memery size limit. <code>lambda_timeout</code>: timeout for the lambda in seconds. <code>config</code>: configuration for the lambda function. Token path will be read by default from the module. <pre>object({    schedule_expression = optional(string, \"rate(1 day)\")    state               = optional(string, \"ENABLED\")    lambda_memory_size  = optional(number, 512)    lambda_timeout      = optional(number, 60)    config = object({      tokenPath      = optional(string)      minimumDaysOld = optional(number, 1)      dryRun         = optional(bool, false)    })  })</pre> <pre>{  \"config\": {}}</pre> no ssm_paths The root path used in SSM to store configuration and secrets. <pre>object({    root   = string    tokens = string    config = string  })</pre> n/a yes subnet_ids List of subnets in which the action runners will be launched, the subnets needs to be subnets in the <code>vpc_id</code>. <code>list(string)</code> n/a yes tags Map of tags that will be added to created resources. By default resources will be tagged with name. <code>map(string)</code> <code>{}</code> no tracing_config Configuration for lambda tracing. <pre>object({    mode                  = optional(string, null)    capture_http_requests = optional(bool, false)    capture_error         = optional(bool, false)  })</pre> <code>{}</code> no userdata_content Alternative user-data content, replacing the templated one. By providing your own user_data you have to take care of installing all required software, including the action runner and registering the runner.  Be-aware configuration paramaters in SSM as well as tags are treated as internals. Changes will not trigger a breaking release. <code>string</code> <code>null</code> no userdata_post_install User-data script snippet to insert after GitHub action runner install <code>string</code> <code>\"\"</code> no userdata_pre_install User-data script snippet to insert before GitHub action runner install <code>string</code> <code>\"\"</code> no userdata_template Alternative user-data template file path, replacing the default template. By providing your own user_data you have to take care of installing all required software, including the action runner. Variables userdata_pre/post_install are ignored. <code>string</code> <code>null</code> no vpc_id The VPC for the security groups. <code>string</code> n/a yes"},{"location":"modules/internal/runners/#outputs","title":"Outputs","text":"Name Description lambda_pool n/a lambda_pool_log_group n/a lambda_scale_down n/a lambda_scale_down_log_group n/a lambda_scale_up n/a lambda_scale_up_log_group n/a launch_template n/a logfiles List of logfiles to send to CloudWatch. Object description: <code>log_group_name</code>: Name of the log group, <code>file_path</code>: path to the log file, <code>log_stream_name</code>: name of the log stream. role_pool n/a role_runner n/a role_scale_down n/a role_scale_up n/a runners_log_groups List of log groups from different log files of runner machine."},{"location":"modules/internal/ssm/","title":"Module - AWS System Manager Parameter store","text":"<p>This module is treated as internal module, breaking changes will not trigger a major release bump.</p> <p>This module is used for storing configuration of runners, registration tokens and secrets for the Lambda's in AWS System Manager Parameter store.</p>"},{"location":"modules/internal/ssm/#requirements","title":"Requirements","text":"Name Version terraform &gt;= 1.3.0 aws ~&gt; 5.27"},{"location":"modules/internal/ssm/#providers","title":"Providers","text":"Name Version aws ~&gt; 5.27"},{"location":"modules/internal/ssm/#modules","title":"Modules","text":"<p>No modules.</p>"},{"location":"modules/internal/ssm/#resources","title":"Resources","text":"Name Type aws_ssm_parameter.github_app_id resource aws_ssm_parameter.github_app_key_base64 resource aws_ssm_parameter.github_app_webhook_secret resource"},{"location":"modules/internal/ssm/#inputs","title":"Inputs","text":"Name Description Type Default Required github_app GitHub app parameters, see your github app. Ensure the key is the base64-encoded <code>.pem</code> file (the output of <code>base64 app.private-key.pem</code>, not the content of <code>private-key.pem</code>). <pre>object({    key_base64     = string    id             = string    webhook_secret = string  })</pre> n/a yes kms_key_arn Optional CMK Key ARN to be used for Parameter Store. <code>string</code> <code>null</code> no path_prefix The path prefix used for naming resources <code>string</code> n/a yes tags Map of tags that will be added to created resources. By default resources will be tagged with name and environment. <code>map(string)</code> <code>{}</code> no"},{"location":"modules/internal/ssm/#outputs","title":"Outputs","text":"Name Description parameters n/a"},{"location":"modules/internal/webhook-github-app/","title":"Module - Update GitHub App Webhook","text":"<p>This module is treated as internal module, breaking changes will not trigger a major release bump.</p> <p>This module is using the local executor to run a bash script.</p> <p>This module updates the GitHub App webhook with the endpoint and secret and can be changed with the root module. The module is used to update the webhook after applying the examples.</p>"},{"location":"modules/internal/webhook-github-app/#requirements","title":"Requirements","text":"Name Version terraform &gt;= 1.3.0 null ~&gt; 3"},{"location":"modules/internal/webhook-github-app/#providers","title":"Providers","text":"Name Version null ~&gt; 3"},{"location":"modules/internal/webhook-github-app/#modules","title":"Modules","text":"<p>No modules.</p>"},{"location":"modules/internal/webhook-github-app/#resources","title":"Resources","text":"Name Type null_resource.update_app resource"},{"location":"modules/internal/webhook-github-app/#inputs","title":"Inputs","text":"Name Description Type Default Required github_app GitHub app parameters, see your github app. Ensure the key is the base64-encoded <code>.pem</code> file (the output of <code>base64 app.private-key.pem</code>, not the content of <code>private-key.pem</code>). <pre>object({    key_base64     = string    id             = string    webhook_secret = string  })</pre> n/a yes webhook_endpoint The endpoint to use for the webhook, defaults to the endpoint of the runners module. <code>string</code> n/a yes"},{"location":"modules/internal/webhook-github-app/#outputs","title":"Outputs","text":"<p>No outputs.</p>"},{"location":"modules/internal/webhook/","title":"Module - GitHub App web hook","text":"<p>This module is treated as internal module, breaking changes will not trigger a major release bump.</p> <p>The module can be deployed in two modes. 'Direct' messages, are delivered directly to the runner queues. 'EventBridge' messages are delivered to an EventBridge bus and then dispatched to the runner queues.</p>"},{"location":"modules/internal/webhook/#lambda-function","title":"Lambda Function","text":"<p>The Lambda function is written in TypeScript and requires Node and yarn. Sources are located in [./lambdas/webhook]. Check see <code>lambda.ts</code> for the different handler functions available.</p>"},{"location":"modules/internal/webhook/#install","title":"Install","text":"<pre><code>cd lambdas/webhook\nyarn install\n</code></pre>"},{"location":"modules/internal/webhook/#test","title":"Test","text":"<p>Test are implemented with Jest, calls to AWS and GitHub are mocked.</p> <pre><code>yarn run test\n</code></pre>"},{"location":"modules/internal/webhook/#package","title":"Package","text":"<p>To compile all TypeScript/JavaScript sources in a single file ncc is used.</p> <pre><code>yarn run dist\n</code></pre>"},{"location":"modules/internal/webhook/#requirements","title":"Requirements","text":"Name Version terraform &gt;= 1.3.0 aws ~&gt; 5.27 null ~&gt; 3"},{"location":"modules/internal/webhook/#providers","title":"Providers","text":"Name Version aws ~&gt; 5.27"},{"location":"modules/internal/webhook/#modules","title":"Modules","text":"Name Source Version direct ./direct n/a eventbridge ./eventbridge n/a"},{"location":"modules/internal/webhook/#resources","title":"Resources","text":"Name Type aws_apigatewayv2_api.webhook resource aws_apigatewayv2_integration.webhook resource aws_apigatewayv2_route.webhook resource aws_apigatewayv2_stage.webhook resource aws_ssm_parameter.runner_matcher_config resource"},{"location":"modules/internal/webhook/#inputs","title":"Inputs","text":"Name Description Type Default Required aws_partition (optional) partition for the base arn if not 'aws' <code>string</code> <code>\"aws\"</code> no eventbridge Enable the use of EventBridge by the module. By enabling this feature events will be put on the EventBridge by the webhook instead of directly dispatching to queues for scaling. <code>enable</code>: Enable the EventBridge feature. <code>accept_events</code>: List can be used to only allow specific events to be putted on the EventBridge. By default all events, empty list will be be interpreted as all events. <pre>object({    enable        = optional(bool, false)    accept_events = optional(list(string), null)  })</pre> n/a yes github_app_parameters Parameter Store for GitHub App Parameters. <pre>object({    webhook_secret = map(string)  })</pre> n/a yes kms_key_arn Optional CMK Key ARN to be used for Parameter Store. <code>string</code> <code>null</code> no lambda_architecture AWS Lambda architecture. Lambda functions using Graviton processors ('arm64') tend to have better price/performance than 'x86_64' functions. <code>string</code> <code>\"arm64\"</code> no lambda_memory_size Memory size limit in MB for lambda. <code>number</code> <code>256</code> no lambda_runtime AWS Lambda runtime. <code>string</code> <code>\"nodejs22.x\"</code> no lambda_s3_bucket S3 bucket from which to specify lambda functions. This is an alternative to providing local files directly. <code>string</code> <code>null</code> no lambda_security_group_ids List of security group IDs associated with the Lambda function. <code>list(string)</code> <code>[]</code> no lambda_subnet_ids List of subnets in which the action runners will be launched, the subnets needs to be subnets in the <code>vpc_id</code>. <code>list(string)</code> <code>[]</code> no lambda_tags Map of tags that will be added to all the lambda function resources. Note these are additional tags to the default tags. <code>map(string)</code> <code>{}</code> no lambda_timeout Time out of the lambda in seconds. <code>number</code> <code>10</code> no lambda_zip File location of the lambda zip file. <code>string</code> <code>null</code> no log_level Logging level for lambda logging. Valid values are  'silly', 'trace', 'debug', 'info', 'warn', 'error', 'fatal'. <code>string</code> <code>\"info\"</code> no logging_kms_key_id Specifies the kms key id to encrypt the logs with <code>string</code> <code>null</code> no logging_retention_in_days Specifies the number of days you want to retain log events for the lambda log group. Possible values are: 0, 1, 3, 5, 7, 14, 30, 60, 90, 120, 150, 180, 365, 400, 545, 731, 1827, and 3653. <code>number</code> <code>180</code> no matcher_config_parameter_store_tier The tier of the parameter store for the matcher configuration. Valid values are <code>Standard</code>, and <code>Advanced</code>. <code>string</code> <code>\"Standard\"</code> no prefix The prefix used for naming resources <code>string</code> <code>\"github-actions\"</code> no repository_white_list List of github repository full names (owner/repo_name) that will be allowed to use the github app. Leave empty for no filtering. <code>list(string)</code> <code>[]</code> no role_path The path that will be added to the role; if not set, the environment name will be used. <code>string</code> <code>null</code> no role_permissions_boundary Permissions boundary that will be added to the created role for the lambda. <code>string</code> <code>null</code> no runner_matcher_config SQS queue to publish accepted build events based on the runner type. When exact match is disabled the webhook accepts the event if one of the workflow job labels is part of the matcher. The priority defines the order the matchers are applied. <pre>map(object({    arn = string    id  = string    matcherConfig = object({      labelMatchers = list(list(string))      exactMatch    = bool      priority      = optional(number, 999)    })  }))</pre> n/a yes ssm_paths The root path used in SSM to store configuration and secrets. <pre>object({    root    = string    webhook = string  })</pre> n/a yes tags Map of tags that will be added to created resources. By default resources will be tagged with name and environment. <code>map(string)</code> <code>{}</code> no tracing_config Configuration for lambda tracing. <pre>object({    mode                  = optional(string, null)    capture_http_requests = optional(bool, false)    capture_error         = optional(bool, false)  })</pre> <code>{}</code> no webhook_lambda_apigateway_access_log_settings Access log settings for webhook API gateway. <pre>object({    destination_arn = string    format          = string  })</pre> <code>null</code> no webhook_lambda_s3_key S3 key for webhook lambda function. Required if using S3 bucket to specify lambdas. <code>string</code> <code>null</code> no webhook_lambda_s3_object_version S3 object version for webhook lambda function. Useful if S3 versioning is enabled on source bucket. <code>string</code> <code>null</code> no"},{"location":"modules/internal/webhook/#outputs","title":"Outputs","text":"Name Description dispatcher n/a endpoint_relative_path n/a eventbridge n/a gateway n/a lambda n/a lambda_log_group n/a role n/a webhook n/a"},{"location":"modules/public/ami-housekeeper/","title":"Module - AMI Housekeeper","text":"<p>This module deploys a Lambda function responsible for deleting outdated AMIs. You can specify various criteria for the deletion process. Please note that the creation of AMIs is not within the scope of this project; the Lambda's role is solely to remove old ones. To avoid potential conflicts, it is recommended to deploy this module only once.</p> <p>By default, the Lambda will scan all launch templates and assume that only the default version is in use. Any other AMIs referenced in the launch templates will be considered outdated and subject to deletion. Additionally, the module can search for AMIs referenced in AWS Systems Manager (SSM). When you set ssmParameterNames to *ami-id, the module will regard all AMIs referenced in SSM as in use, sparing them from deletion.</p> <p>You can further refine the deletion process by applying AMI filters, such as those based on tags. The module also offers a 'dry run' option, allowing you to test the Lambda's behavior before executing actual deletions.</p>"},{"location":"modules/public/ami-housekeeper/#usages","title":"Usages","text":"<p>The module can be activated via the main module by setting <code>enable_ami_housekeeper</code> to <code>true</code>. Or invoking the module directly.</p> <pre><code>module \"ami_housekeeper\" {\n  source = \"path to module\"\n\n  prefix = \"my-prefix\"\n\n  ami_cleanup_config = {\n    ssmParameterNames = [\"*/ami-id\"]\n    minimumDaysOld    = 30\n    filters = [\n      {\n        Name   = \"tag:Packer\"\n        Values = [\"true\"]\n      }\n    ]\n    dryRun = true\n  }\n\n  log_level = \"debug\"\n}\n</code></pre>"},{"location":"modules/public/ami-housekeeper/#development","title":"Development","text":""},{"location":"modules/public/ami-housekeeper/#lambda-function","title":"Lambda Function","text":"<p>The Lambda function is written in TypeScript and requires Node and yarn. Sources are located in [https://github.com/github-aws-runners/terraform-aws-github-runner/tree/main/lambdas].</p>"},{"location":"modules/public/ami-housekeeper/#install","title":"Install","text":"<pre><code>cd lambdas\nyarn install\n</code></pre>"},{"location":"modules/public/ami-housekeeper/#test","title":"Test","text":"<p>Test are implemented with Jest, calls to AWS and GitHub are mocked.</p> <pre><code>yarn run test\n</code></pre>"},{"location":"modules/public/ami-housekeeper/#package","title":"Package","text":"<p>To compile all TypeScript/JavaScript sources in a single file ncc is used.</p> <pre><code>yarn run dist\n</code></pre>"},{"location":"modules/public/ami-housekeeper/#requirements","title":"Requirements","text":"Name Version terraform &gt;= 1.3.0 aws ~&gt; 5.27"},{"location":"modules/public/ami-housekeeper/#providers","title":"Providers","text":"Name Version aws ~&gt; 5.27"},{"location":"modules/public/ami-housekeeper/#modules","title":"Modules","text":"<p>No modules.</p>"},{"location":"modules/public/ami-housekeeper/#resources","title":"Resources","text":"Name Type aws_cloudwatch_event_rule.ami_housekeeper resource aws_cloudwatch_event_target.ami_housekeeper resource aws_cloudwatch_log_group.ami_housekeeper resource aws_iam_role.ami_housekeeper resource aws_iam_role_policy.ami_housekeeper resource aws_iam_role_policy.ami_housekeeper_xray resource aws_iam_role_policy.lambda_logging resource aws_iam_role_policy_attachment.ami_housekeeper_vpc_execution_role resource aws_lambda_function.ami_housekeeper resource aws_lambda_permission.ami_housekeeper resource aws_iam_policy_document.lambda_assume_role_policy data source aws_iam_policy_document.lambda_xray data source"},{"location":"modules/public/ami-housekeeper/#inputs","title":"Inputs","text":"Name Description Type Default Required aws_partition (optional) partition for the base arn if not 'aws' <code>string</code> <code>\"aws\"</code> no cleanup_config Configuration for AMI cleanup. <code>amiFilters</code> - Filters to use when searching for AMIs to cleanup. Default filter for images owned by the account and that are available. <code>dryRun</code> - If true, no AMIs will be deregistered. Default false. <code>launchTemplateNames</code> - Launch template names to use when searching for AMIs to cleanup. Default no launch templates. <code>maxItems</code> - The maximum numer of AMI's tha will be queried for cleanup. Default no maximum. <code>minimumDaysOld</code> - Minimum number of days old an AMI must be to be considered for cleanup. Default 30. <code>ssmParameterNames</code> - SSM parameter names to use when searching for AMIs to cleanup. This parameter should be set when using SSM to configure the AMI to use. Default no SSM parameters. <pre>object({    amiFilters = optional(list(object({      Name   = string      Values = list(string)      })),      [{        Name : \"state\",        Values : [\"available\"],        },        {          Name : \"image-type\",          Values : [\"machine\"],      }]    )    dryRun              = optional(bool, false)    launchTemplateNames = optional(list(string))    maxItems            = optional(number)    minimumDaysOld      = optional(number, 30)    ssmParameterNames   = optional(list(string))  })</pre> <code>{}</code> no lambda_architecture AWS Lambda architecture. Lambda functions using Graviton processors ('arm64') tend to have better price/performance than 'x86_64' functions. <code>string</code> <code>\"arm64\"</code> no lambda_memory_size Memory size linit in MB of the lambda. <code>number</code> <code>256</code> no lambda_principals (Optional) add extra principals to the role created for execution of the lambda, e.g. for local testing. <pre>list(object({    type        = string    identifiers = list(string)  }))</pre> <code>[]</code> no lambda_runtime AWS Lambda runtime. <code>string</code> <code>\"nodejs22.x\"</code> no lambda_s3_bucket S3 bucket from which to specify lambda functions. This is an alternative to providing local files directly. <code>string</code> <code>null</code> no lambda_s3_key S3 key for syncer lambda function. Required if using S3 bucket to specify lambdas. <code>string</code> <code>null</code> no lambda_s3_object_version S3 object version for syncer lambda function. Useful if S3 versioning is enabled on source bucket. <code>string</code> <code>null</code> no lambda_schedule_expression Scheduler expression for action runner binary syncer. <code>string</code> <code>\"rate(1 day)\"</code> no lambda_security_group_ids List of security group IDs associated with the Lambda function. <code>list(string)</code> <code>[]</code> no lambda_subnet_ids List of subnets in which the action runners will be launched, the subnets needs to be subnets in the <code>vpc_id</code>. <code>list(string)</code> <code>[]</code> no lambda_tags Map of tags that will be added to all the lambda function resources. Note these are additional tags to the default tags. <code>map(string)</code> <code>{}</code> no lambda_timeout Time out of the lambda in seconds. <code>number</code> <code>60</code> no lambda_zip File location of the lambda zip file. <code>string</code> <code>null</code> no log_level Logging level for lambda logging. Valid values are  'silly', 'trace', 'debug', 'info', 'warn', 'error', 'fatal'. <code>string</code> <code>\"info\"</code> no logging_kms_key_id Specifies the kms key id to encrypt the logs with <code>string</code> <code>null</code> no logging_retention_in_days Specifies the number of days you want to retain log events for the lambda log group. Possible values are: 0, 1, 3, 5, 7, 14, 30, 60, 90, 120, 150, 180, 365, 400, 545, 731, 1827, and 3653. <code>number</code> <code>180</code> no prefix The prefix used for naming resources <code>string</code> <code>\"github-actions\"</code> no role_path The path that will be added to the role, if not set the environment name will be used. <code>string</code> <code>null</code> no role_permissions_boundary Permissions boundary that will be added to the created role for the lambda. <code>string</code> <code>null</code> no state_event_rule_ami_housekeeper State of the rule. <code>string</code> <code>\"ENABLED\"</code> no tags Map of tags that will be added to created resources. By default resources will be tagged with name and environment. <code>map(string)</code> <code>{}</code> no tracing_config Configuration for lambda tracing. <pre>object({    mode                  = optional(string, null)    capture_http_requests = optional(bool, false)    capture_error         = optional(bool, false)  })</pre> <code>{}</code> no"},{"location":"modules/public/ami-housekeeper/#outputs","title":"Outputs","text":"Name Description lambda n/a lambda_log_group n/a lambda_role n/a"},{"location":"modules/public/download-lambda/","title":"Module - Download lambda artifacts","text":"<p>This module is optional and provides an option to download via Terraform the Lambda artifacts from GitHub.</p>"},{"location":"modules/public/download-lambda/#usages","title":"Usages","text":"<pre><code>module \"lambdas\" {\n  source = \"&lt;source location&gt;\"\n  lambdas = [\n    {\n      name = \"webhook\"\n      tag  = \"v0.15.0\"\n    },\n    {\n      name = \"runners\"\n      tag  = \"v0.15.0\"\n    },\n    {\n      name = \"runner-binaries-syncer\"\n      tag  = \"v0.15.0\"\n    }\n  ]\n}\n</code></pre>"},{"location":"modules/public/download-lambda/#requirements","title":"Requirements","text":"Name Version terraform &gt;= 1.3.0 aws ~&gt; 5.27 null ~&gt; 3"},{"location":"modules/public/download-lambda/#providers","title":"Providers","text":"Name Version null ~&gt; 3"},{"location":"modules/public/download-lambda/#modules","title":"Modules","text":"<p>No modules.</p>"},{"location":"modules/public/download-lambda/#resources","title":"Resources","text":"Name Type null_resource.download resource"},{"location":"modules/public/download-lambda/#inputs","title":"Inputs","text":"Name Description Type Default Required lambdas Name and tag for lambdas to download. <pre>list(object({    name = string    tag  = string  }))</pre> n/a yes"},{"location":"modules/public/download-lambda/#outputs","title":"Outputs","text":"Name Description files n/a"},{"location":"modules/public/multi-runner/","title":"Module - Multi runner","text":"<p>This module replaces the top-level module to make it easy to create with one deployment multiple type of runners.</p> <p>This module creates many runners with a single GitHub app. The module utilizes the internal modules and deploys parts of the stack for each runner defined.</p> <p>The module takes a configuration as input containing a matcher for the labels. The webhook lambda is using the configuration to delegate events based on the labels in the workflow job and sent them to a dedicated queue based on the configuration. Events on each queue are processed by a dedicated lambda per configuration to scale runners.</p> <p>For each configuration:</p> <ul> <li>When enabled, the distribution syncer is deployed for each unique combination of OS and architecture.</li> <li>For each configuration a queue is created and runner module is deployed</li> </ul>"},{"location":"modules/public/multi-runner/#matching","title":"Matching","text":"<p>Matching of the configuration is done based on the labels specified in labelMatchers configuration. The webhook is processing the <code>workflow_job</code> event and match the labels against the labels specified in labelMatchers configuration in the order of configuration with exact-match true first, followed by all exact matches false.</p>"},{"location":"modules/public/multi-runner/#the-catch","title":"The catch","text":"<p>Controlling which event is taken up by which runner is not to this module. It is completely done by GitHub. This means when potentially different runners can run the same job there is nothing that can be done to guarantee a certain runner will take up the job.</p> <p>An example, given you have two runners one with the labels. <code>self-hosted, linux, x64, large</code> and one with the labels <code>self-hosted, linux, x64, small</code>. Once you define a subset of the labels in the workflow, for example <code>self-hosted, linux, x64</code>. Both runners can take the job potentially. You can define to scale one of the runners for the event, but still there is no guarantee that the scaled runner takes the job. The workflow with subset of labels (<code>self-hosted, linux, x64</code>) can take up runner with specific labels (<code>self-hosted, linux, x64, large</code>) and leave the workflow with labels (<code>self-hosted, linux, x64, large</code>) be without the runner. The only mitigation that is available right now is to use a small pool of runners. Pool instances can also exist for a short amount of time and only created once in x time based on a cron expression.</p> <p>Jobs not defining all all labels but for example only <code>[self-hosted, linux]</code> could be matched to potentially different runners. The matcher scales the first runner that matches. With the attribute <code>priority</code> the order of matchers can be defined.</p>"},{"location":"modules/public/multi-runner/#usages","title":"Usages","text":"<p>A complete example is available in the examples, see the multi-runner example for actual implementation.</p> <pre><code>module \"multi-runner\" {\n  prefix = \"multi-runner\"\n\n  github_app = {\n    # app details\n  }\n\n  multi_runner_config = {\n    \"linux-arm\" = {\n      matcherConfig : {\n        labelMatchers = [[\"self-hosted\", \"linux\", \"arm64\", \"arm\"]]\n        exactMatch    = true\n      }\n      runner_config = {\n        runner_os                      = \"linux\"\n        runner_architecture            = \"arm64\"\n        runner_extra_labels            = \"arm\"\n        enable_ssm_on_runners          = true\n        instance_types                 = [\"t4g.large\", \"c6g.large\"]\n        ...\n      }\n      ...\n    },\n    \"linux-x64\" = {\n      matcherConfig : {\n        labelMatchers = [[\"self-hosted\", \"linux\", \"x64\"]]\n        exactMatch    = false\n      }\n      runner_config = {\n        runner_os                       = \"linux\"\n        runner_architecture             = \"x64\"\n        instance_types                  = [\"m5ad.large\", \"m5a.large\"]\n        enable_ephemeral_runners        = true\n        delay_webhook_event = 0\n        ...\n      }\n      ...\n    }\n  }\n\n}\n</code></pre>"},{"location":"modules/public/multi-runner/#requirements","title":"Requirements","text":"Name Version terraform &gt;= 1.3 aws ~&gt; 5.77 random ~&gt; 3.0"},{"location":"modules/public/multi-runner/#providers","title":"Providers","text":"Name Version aws ~&gt; 5.77 random ~&gt; 3.0"},{"location":"modules/public/multi-runner/#modules","title":"Modules","text":"Name Source Version ami_housekeeper ../ami-housekeeper n/a instance_termination_watcher ../termination-watcher n/a runner_binaries ../runner-binaries-syncer n/a runners ../runners n/a ssm ../ssm n/a webhook ../webhook n/a"},{"location":"modules/public/multi-runner/#resources","title":"Resources","text":"Name Type aws_sqs_queue.queued_builds resource aws_sqs_queue.queued_builds_dlq resource aws_sqs_queue_policy.build_queue_dlq_policy resource aws_sqs_queue_policy.build_queue_policy resource random_string.random resource aws_iam_policy_document.deny_unsecure_transport data source"},{"location":"modules/public/multi-runner/#inputs","title":"Inputs","text":"Name Description Type Default Required ami_housekeeper_cleanup_config Configuration for AMI cleanup. <pre>object({    maxItems       = optional(number)    minimumDaysOld = optional(number)    amiFilters = optional(list(object({      Name   = string      Values = list(string)    })))    launchTemplateNames = optional(list(string))    ssmParameterNames   = optional(list(string))    dryRun              = optional(bool)  })</pre> <code>{}</code> no ami_housekeeper_lambda_memory_size Memory size linit in MB of the lambda. <code>number</code> <code>256</code> no ami_housekeeper_lambda_s3_key S3 key for syncer lambda function. Required if using S3 bucket to specify lambdas. <code>string</code> <code>null</code> no ami_housekeeper_lambda_s3_object_version S3 object version for syncer lambda function. Useful if S3 versioning is enabled on source bucket. <code>string</code> <code>null</code> no ami_housekeeper_lambda_schedule_expression Scheduler expression for action runner binary syncer. <code>string</code> <code>\"cron(11 7 * * ? *)\"</code> no ami_housekeeper_lambda_timeout Time out of the lambda in seconds. <code>number</code> <code>300</code> no ami_housekeeper_lambda_zip File location of the lambda zip file. <code>string</code> <code>null</code> no associate_public_ipv4_address Associate public IPv4 with the runner. Only tested with IPv4 <code>bool</code> <code>false</code> no aws_partition (optiona) partition in the arn namespace to use if not 'aws' <code>string</code> <code>\"aws\"</code> no aws_region AWS region. <code>string</code> n/a yes cloudwatch_config (optional) Replaces the module default cloudwatch log config. See https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-Agent-Configuration-File-Details.html for details. <code>string</code> <code>null</code> no enable_ami_housekeeper Option to disable the lambda to clean up old AMIs. <code>bool</code> <code>false</code> no enable_managed_runner_security_group Enabling the default managed security group creation. Unmanaged security groups can be specified via <code>runner_additional_security_group_ids</code>. <code>bool</code> <code>true</code> no eventbridge Enable the use of EventBridge by the module. By enabling this feature events will be put on the EventBridge by the webhook instead of directly dispatching to queues for scaling. <pre>object({    enable        = optional(bool, true)    accept_events = optional(list(string), [])  })</pre> <code>{}</code> no ghes_ssl_verify GitHub Enterprise SSL verification. Set to 'false' when custom certificate (chains) is used for GitHub Enterprise Server (insecure). <code>bool</code> <code>true</code> no ghes_url GitHub Enterprise Server URL. Example: https://github.internal.co - DO NOT SET IF USING PUBLIC GITHUB <code>string</code> <code>null</code> no github_app GitHub app parameters, see your github app. Ensure the key is the base64-encoded <code>.pem</code> file (the output of <code>base64 app.private-key.pem</code>, not the content of <code>private-key.pem</code>). <pre>object({    key_base64     = string    id             = string    webhook_secret = string  })</pre> n/a yes instance_profile_path The path that will be added to the instance_profile, if not set the environment name will be used. <code>string</code> <code>null</code> no instance_termination_watcher Configuration for the spot termination watcher lambda function. This feature is Beta, changes will not trigger a major release as long in beta.<code>enable</code>: Enable or disable the spot termination watcher.<code>memory_size</code>: Memory size linit in MB of the lambda.<code>s3_key</code>: S3 key for syncer lambda function. Required if using S3 bucket to specify lambdas.<code>s3_object_version</code>: S3 object version for syncer lambda function. Useful if S3 versioning is enabled on source bucket.<code>timeout</code>: Time out of the lambda in seconds.<code>zip</code>: File location of the lambda zip file. <pre>object({    enable = optional(bool, false)    features = optional(object({      enable_spot_termination_handler              = optional(bool, true)      enable_spot_termination_notification_watcher = optional(bool, true)    }), {})    memory_size       = optional(number, null)    s3_key            = optional(string, null)    s3_object_version = optional(string, null)    timeout           = optional(number, null)    zip               = optional(string, null)  })</pre> <code>{}</code> no key_name Key pair name <code>string</code> <code>null</code> no kms_key_arn Optional CMK Key ARN to be used for Parameter Store. <code>string</code> <code>null</code> no lambda_architecture AWS Lambda architecture. Lambda functions using Graviton processors ('arm64') tend to have better price/performance than 'x86_64' functions. <code>string</code> <code>\"arm64\"</code> no lambda_principals (Optional) add extra principals to the role created for execution of the lambda, e.g. for local testing. <pre>list(object({    type        = string    identifiers = list(string)  }))</pre> <code>[]</code> no lambda_runtime AWS Lambda runtime. <code>string</code> <code>\"nodejs22.x\"</code> no lambda_s3_bucket S3 bucket from which to specify lambda functions. This is an alternative to providing local files directly. <code>string</code> <code>null</code> no lambda_security_group_ids List of security group IDs associated with the Lambda function. <code>list(string)</code> <code>[]</code> no lambda_subnet_ids List of subnets in which the action runners will be launched, the subnets needs to be subnets in the <code>vpc_id</code>. <code>list(string)</code> <code>[]</code> no lambda_tags Map of tags that will be added to all the lambda function resources. Note these are additional tags to the default tags. <code>map(string)</code> <code>{}</code> no log_level Logging level for lambda logging. Valid values are  'silly', 'trace', 'debug', 'info', 'warn', 'error', 'fatal'. <code>string</code> <code>\"info\"</code> no logging_kms_key_id Specifies the kms key id to encrypt the logs with <code>string</code> <code>null</code> no logging_retention_in_days Specifies the number of days you want to retain log events for the lambda log group. Possible values are: 0, 1, 3, 5, 7, 14, 30, 60, 90, 120, 150, 180, 365, 400, 545, 731, 1827, and 3653. <code>number</code> <code>180</code> no matcher_config_parameter_store_tier The tier of the parameter store for the matcher configuration. Valid values are <code>Standard</code>, and <code>Advanced</code>. <code>string</code> <code>\"Standard\"</code> no metrics Configuration for metrics created by the module, by default metrics are disabled to avoid additional costs. When metrics are enable all metrics are created unless explicit configured otherwise. <pre>object({    enable    = optional(bool, false)    namespace = optional(string, \"GitHub Runners\")    metric = optional(object({      enable_github_app_rate_limit    = optional(bool, true)      enable_job_retry                = optional(bool, true)      enable_spot_termination_warning = optional(bool, true)    }), {})  })</pre> <code>{}</code> no multi_runner_config multi_runner_config = {      runner_config: {        runner_os: \"The EC2 Operating System type to use for action runner instances (linux,windows).\"        runner_architecture: \"The platform architecture of the runner instance_type.\"        runner_metadata_options: \"(Optional) Metadata options for the ec2 runner instances.\"        ami_filter: \"(Optional) List of maps used to create the AMI filter for the action runner AMI. By default amazon linux 2 is used.\"        ami_owners: \"(Optional) The list of owners used to select the AMI of action runner instances.\"        create_service_linked_role_spot: (Optional) create the serviced linked role for spot instances that is required by the scale-up lambda.        credit_specification: \"(Optional) The credit specification of the runner instance_type. Can be unset, <code>standard</code> or <code>unlimited</code>.        delay_webhook_event: \"The number of seconds the event accepted by the webhook is invisible on the queue before the scale up lambda will receive the event.\"        disable_runner_autoupdate: \"Disable the auto update of the github runner agent. Be aware there is a grace period of 30 days, see also the GitHub article\"        ebs_optimized: \"The EC2 EBS optimized configuration.\"        enable_ephemeral_runners: \"Enable ephemeral runners, runners will only be used once.\"        enable_job_queued_check: \"Enables JIT configuration for creating runners instead of registration token based registraton. JIT configuration will only be applied for ephemeral runners. By default JIT confiugration is enabled for ephemeral runners an can be disabled via this override. When running on GHES without support for JIT configuration this variable should be set to true for ephemeral runners.\"        enable_on_demand_failover_for_errors: \"Enable on-demand failover. For example to fall back to on demand when no spot capacity is available the variable can be set to <code>InsufficientInstanceCapacity</code>. When not defined the default behavior is to retry later.\"        enable_organization_runners: \"Register runners to organization, instead of repo level\"        enable_runner_binaries_syncer: \"Option to disable the lambda to sync GitHub runner distribution, useful when using a pre-build AMI.\"        enable_ssm_on_runners: \"Enable to allow access the runner instances for debugging purposes via SSM. Note that this adds additional permissions to the runner instances.\"        enable_userdata: \"Should the userdata script be enabled for the runner. Set this to false if you are using your own prebuilt AMI.\"        instance_allocation_strategy: \"The allocation strategy for spot instances. AWS recommends to use <code>capacity-optimized</code> however the AWS default is <code>lowest-price</code>.\"        instance_max_spot_price: \"Max price price for spot intances per hour. This variable will be passed to the create fleet as max spot price for the fleet.\"        instance_target_capacity_type: \"Default lifecycle used for runner instances, can be either <code>spot</code> or <code>on-demand</code>.\"        instance_types: \"List of instance types for the action runner. Defaults are based on runner_os (al2023 for linux and Windows Server Core for win).\"        job_queue_retention_in_seconds: \"The number of seconds the job is held in the queue before it is purged\"        minimum_running_time_in_minutes: \"The time an ec2 action runner should be running at minimum before terminated if not busy.\"        pool_runner_owner: \"The pool will deploy runners to the GitHub org ID, set this value to the org to which you want the runners deployed. Repo level is not supported.\"        runner_additional_security_group_ids: \"List of additional security groups IDs to apply to the runner. If added outside the multi_runner_config block, the additional security group(s) will be applied to all runner configs. If added inside the multi_runner_config, the additional security group(s) will be applied to the individual runner.\"        runner_as_root: \"Run the action runner under the root user. Variable <code>runner_run_as</code> will be ignored.\"        runner_boot_time_in_minutes: \"The minimum time for an EC2 runner to boot and register as a runner.\"        runner_disable_default_labels: \"Disable default labels for the runners (os, architecture and <code>self-hosted</code>). If enabled, the runner will only have the extra labels provided in <code>runner_extra_labels</code>. In case you on own start script is used, this configuration parameter needs to be parsed via SSM.\"        runner_extra_labels: \"Extra (custom) labels for the runners (GitHub). Separate each label by a comma. Labels checks on the webhook can be enforced by setting <code>multi_runner_config.matcherConfig.exactMatch</code>. GitHub read-only labels should not be provided.\"        runner_group_name: \"Name of the runner group.\"        runner_name_prefix: \"Prefix for the GitHub runner name.\"        runner_run_as: \"Run the GitHub actions agent as user.\"        runners_maximum_count: \"The maximum number of runners that will be created. Setting the variable to <code>-1</code> desiables the maximum check.\"        scale_down_schedule_expression: \"Scheduler expression to check every x for scale down.\"        scale_up_reserved_concurrent_executions: \"Amount of reserved concurrent executions for the scale-up lambda function. A value of 0 disables lambda from being triggered and -1 removes any concurrency limitations.\"        userdata_template: \"Alternative user-data template, replacing the default template. By providing your own user_data you have to take care of installing all required software, including the action runner. Variables userdata_pre/post_install are ignored.\"        enable_jit_config \"Overwrite the default behavior for JIT configuration. By default JIT configuration is enabled for ephemeral runners and disabled for non-ephemeral runners. In case of GHES check first if the JIT config API is avaialbe. In case you upgradeing from 3.x to 4.x you can set <code>enable_jit_config</code> to <code>false</code> to avoid a breaking change when having your own AMI.\"        enable_runner_detailed_monitoring: \"Should detailed monitoring be enabled for the runner. Set this to true if you want to use detailed monitoring. See https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-cloudwatch-new.html for details.\"        enable_cloudwatch_agent: \"Enabling the cloudwatch agent on the ec2 runner instances, the runner contains default config. Configuration can be overridden via <code>cloudwatch_config</code>.\"        cloudwatch_config: \"(optional) Replaces the module default cloudwatch log config. See https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-Agent-Configuration-File-Details.html for details.\"        userdata_pre_install: \"Script to be ran before the GitHub Actions runner is installed on the EC2 instances\"        userdata_post_install: \"Script to be ran after the GitHub Actions runner is installed on the EC2 instances\"        runner_hook_job_started: \"Script to be ran in the runner environment at the beginning of every job\"        runner_hook_job_completed: \"Script to be ran in the runner environment at the end of every job\"        runner_ec2_tags: \"Map of tags that will be added to the launch template instance tag specifications.\"        runner_iam_role_managed_policy_arns: \"Attach AWS or customer-managed IAM policies (by ARN) to the runner IAM role\"        vpc_id: \"The VPC for security groups of the action runners. If not set uses the value of <code>var.vpc_id</code>.\"        subnet_ids: \"List of subnets in which the action runners will be launched, the subnets needs to be subnets in the <code>vpc_id</code>. If not set, uses the value of <code>var.subnet_ids</code>.\"        idle_config: \"List of time period that can be defined as cron expression to keep a minimum amount of runners active instead of scaling down to 0. By defining this list you can ensure that in time periods that match the cron expression within 5 seconds a runner is kept idle.\"        runner_log_files: \"(optional) Replaces the module default cloudwatch log config. See https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-Agent-Configuration-File-Details.html for details.\"        block_device_mappings: \"The EC2 instance block device configuration. Takes the following keys: <code>device_name</code>, <code>delete_on_termination</code>, <code>volume_type</code>, <code>volume_size</code>, <code>encrypted</code>, <code>iops</code>, <code>throughput</code>, <code>kms_key_id</code>, <code>snapshot_id</code>.\"        job_retry: \"Experimental! Can be removed / changed without trigger a major release. Configure job retries. The configuration enables job retries (for ephemeral runners). After creating the insances a message will be published to a job retry queue. The job retry check lambda is checking after a delay if the job is queued. If not the message will be published again on the scale-up (build queue). Using this feature can impact the reate limit of the GitHub app.\"        pool_config: \"The configuration for updating the pool. The <code>pool_size</code> to adjust to by the events triggered by the <code>schedule_expression</code>. For example you can configure a cron expression for week days to adjust the pool to 10 and another expression for the weekend to adjust the pool to 1. Use <code>schedule_expression_timezone</code> to override the schedule time zone (defaults to UTC).\"      }      matcherConfig: {        labelMatchers: \"The list of list of labels supported by the runner configuration. <code>[[self-hosted, linux, x64, example]]</code>\"        exactMatch: \"If set to true all labels in the workflow job must match the GitHub labels (os, architecture and <code>self-hosted</code>). When false if any workflow label matches it will trigger the webhook.\"        priority: \"If set it defines the priority of the matcher, the matcher with the lowest priority will be evaluated first. Default is 999, allowed values 0-999.\"      }      redrive_build_queue: \"Set options to attach (optional) a dead letter queue to the build queue, the queue between the webhook and the scale up lambda. You have the following options. 1. Disable by setting <code>enabled</code> to false. 2. Enable by setting <code>enabled</code> to <code>true</code>, <code>maxReceiveCount</code> to a number of max retries.\"    } <pre>map(object({    runner_config = object({      runner_os           = string      runner_architecture = string      runner_metadata_options = optional(map(any), {        instance_metadata_tags      = \"enabled\"        http_endpoint               = \"enabled\"        http_tokens                 = \"required\"        http_put_response_hop_limit = 1      })      ami_filter                              = optional(map(list(string)), { state = [\"available\"] })      ami_owners                              = optional(list(string), [\"amazon\"])      ami_id_ssm_parameter_name               = optional(string, null)      ami_kms_key_arn                         = optional(string, \"\")      create_service_linked_role_spot         = optional(bool, false)      credit_specification                    = optional(string, null)      delay_webhook_event                     = optional(number, 30)      disable_runner_autoupdate               = optional(bool, false)      ebs_optimized                           = optional(bool, false)      enable_ephemeral_runners                = optional(bool, false)      enable_job_queued_check                 = optional(bool, null)      enable_on_demand_failover_for_errors    = optional(list(string), [])      enable_organization_runners             = optional(bool, false)      enable_runner_binaries_syncer           = optional(bool, true)      enable_ssm_on_runners                   = optional(bool, false)      enable_userdata                         = optional(bool, true)      instance_allocation_strategy            = optional(string, \"lowest-price\")      instance_max_spot_price                 = optional(string, null)      instance_target_capacity_type           = optional(string, \"spot\")      instance_types                          = list(string)      job_queue_retention_in_seconds          = optional(number, 86400)      minimum_running_time_in_minutes         = optional(number, null)      pool_runner_owner                       = optional(string, null)      runner_as_root                          = optional(bool, false)      runner_boot_time_in_minutes             = optional(number, 5)      runner_disable_default_labels           = optional(bool, false)      runner_extra_labels                     = optional(list(string), [])      runner_group_name                       = optional(string, \"Default\")      runner_name_prefix                      = optional(string, \"\")      runner_run_as                           = optional(string, \"ec2-user\")      runners_maximum_count                   = number      runner_additional_security_group_ids    = optional(list(string), [])      scale_down_schedule_expression          = optional(string, \"cron(/5 * * * ? )\")      scale_up_reserved_concurrent_executions = optional(number, 1)      userdata_template                       = optional(string, null)      userdata_content                        = optional(string, null)      enable_jit_config                       = optional(bool, null)      enable_runner_detailed_monitoring       = optional(bool, false)      enable_cloudwatch_agent                 = optional(bool, true)      cloudwatch_config                       = optional(string, null)      userdata_pre_install                    = optional(string, \"\")      userdata_post_install                   = optional(string, \"\")      runner_hook_job_started                 = optional(string, \"\")      runner_hook_job_completed               = optional(string, \"\")      runner_ec2_tags                         = optional(map(string), {})      runner_iam_role_managed_policy_arns     = optional(list(string), [])      vpc_id                                  = optional(string, null)      subnet_ids                              = optional(list(string), null)      idle_config = optional(list(object({        cron             = string        timeZone         = string        idleCount        = number        evictionStrategy = optional(string, \"oldest_first\")      })), [])      runner_log_files = optional(list(object({        log_group_name   = string        prefix_log_group = bool        file_path        = string        log_stream_name  = string      })), null)      block_device_mappings = optional(list(object({        delete_on_termination = optional(bool, true)        device_name           = optional(string, \"/dev/xvda\")        encrypted             = optional(bool, true)        iops                  = optional(number)        kms_key_id            = optional(string)        snapshot_id           = optional(string)        throughput            = optional(number)        volume_size           = number        volume_type           = optional(string, \"gp3\")        })), [{        volume_size = 30      }])      pool_config = optional(list(object({        schedule_expression          = string        schedule_expression_timezone = optional(string)        size                         = number      })), [])      job_retry = optional(object({        enable             = optional(bool, false)        delay_in_seconds   = optional(number, 300)        delay_backoff      = optional(number, 2)        lambda_memory_size = optional(number, 256)        lambda_timeout     = optional(number, 30)        max_attempts       = optional(number, 1)      }), {})    })    matcherConfig = object({      labelMatchers = list(list(string))      exactMatch    = optional(bool, false)      priority      = optional(number, 999)    })    redrive_build_queue = optional(object({      enabled         = bool      maxReceiveCount = number      }), {      enabled         = false      maxReceiveCount = null    })  }))</pre> n/a yes pool_lambda_reserved_concurrent_executions Amount of reserved concurrent executions for the scale-up lambda function. A value of 0 disables lambda from being triggered and -1 removes any concurrency limitations. <code>number</code> <code>1</code> no pool_lambda_timeout Time out for the pool lambda in seconds. <code>number</code> <code>60</code> no prefix The prefix used for naming resources <code>string</code> <code>\"github-actions\"</code> no queue_encryption Configure how data on queues managed by the modules in ecrypted at REST. Options are encryped via SSE, non encrypted and via KMSS. By default encryptes via SSE is enabled. See for more details the Terraform <code>aws_sqs_queue</code> resource https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/sqs_queue. <pre>object({    kms_data_key_reuse_period_seconds = number    kms_master_key_id                 = string    sqs_managed_sse_enabled           = bool  })</pre> <pre>{  \"kms_data_key_reuse_period_seconds\": null,  \"kms_master_key_id\": null,  \"sqs_managed_sse_enabled\": true}</pre> no repository_white_list List of github repository full names (owner/repo_name) that will be allowed to use the github app. Leave empty for no filtering. <code>list(string)</code> <code>[]</code> no role_path The path that will be added to the role; if not set, the environment name will be used. <code>string</code> <code>null</code> no role_permissions_boundary Permissions boundary that will be added to the created role for the lambda. <code>string</code> <code>null</code> no runner_additional_security_group_ids (optional) List of additional security groups IDs to apply to the runner <code>list(string)</code> <code>[]</code> no runner_binaries_s3_sse_configuration Map containing server-side encryption configuration for runner-binaries S3 bucket. <code>any</code> <pre>{  \"rule\": {    \"apply_server_side_encryption_by_default\": {      \"sse_algorithm\": \"AES256\"    }  }}</pre> no runner_binaries_s3_versioning Status of S3 versioning for runner-binaries S3 bucket. Once set to Enabled the change cannot be reverted via Terraform! <code>string</code> <code>\"Disabled\"</code> no runner_binaries_syncer_lambda_timeout Time out of the binaries sync lambda in seconds. <code>number</code> <code>300</code> no runner_binaries_syncer_lambda_zip File location of the binaries sync lambda zip file. <code>string</code> <code>null</code> no runner_binaries_syncer_memory_size Memory size limit in MB for binary syncer lambda. <code>number</code> <code>256</code> no runner_egress_rules List of egress rules for the GitHub runner instances. <pre>list(object({    cidr_blocks      = list(string)    ipv6_cidr_blocks = list(string)    prefix_list_ids  = list(string)    from_port        = number    protocol         = string    security_groups  = list(string)    self             = bool    to_port          = number    description      = string  }))</pre> <pre>[  {    \"cidr_blocks\": [      \"0.0.0.0/0\"    ],    \"description\": null,    \"from_port\": 0,    \"ipv6_cidr_blocks\": [      \"::/0\"    ],    \"prefix_list_ids\": null,    \"protocol\": \"-1\",    \"security_groups\": null,    \"self\": null,    \"to_port\": 0  }]</pre> no runners_lambda_s3_key S3 key for runners lambda function. Required if using S3 bucket to specify lambdas. <code>string</code> <code>null</code> no runners_lambda_s3_object_version S3 object version for runners lambda function. Useful if S3 versioning is enabled on source bucket. <code>string</code> <code>null</code> no runners_lambda_zip File location of the lambda zip file for scaling runners. <code>string</code> <code>null</code> no runners_scale_down_lambda_timeout Time out for the scale down lambda in seconds. <code>number</code> <code>60</code> no runners_scale_up_lambda_timeout Time out for the scale up lambda in seconds. <code>number</code> <code>30</code> no runners_ssm_housekeeper Configuration for the SSM housekeeper lambda. This lambda deletes token / JIT config from SSM. <code>schedule_expression</code>: is used to configure the schedule for the lambda. <code>enabled</code>: enable or disable the lambda trigger via the EventBridge. <code>lambda_memory_size</code>: lambda memery size limit. <code>lambda_timeout</code>: timeout for the lambda in seconds. <code>config</code>: configuration for the lambda function. Token path will be read by default from the module. <pre>object({    schedule_expression = optional(string, \"rate(1 day)\")    enabled             = optional(bool, true)    lambda_memory_size  = optional(number, 512)    lambda_timeout      = optional(number, 60)    config = object({      tokenPath      = optional(string)      minimumDaysOld = optional(number, 1)      dryRun         = optional(bool, false)    })  })</pre> <pre>{  \"config\": {}}</pre> no scale_down_lambda_memory_size Memory size limit in MB for scale down. <code>number</code> <code>512</code> no scale_up_lambda_memory_size Memory size limit in MB for scale_up lambda. <code>number</code> <code>512</code> no ssm_paths The root path used in SSM to store configuration and secreets. <pre>object({    root    = optional(string, \"github-action-runners\")    app     = optional(string, \"app\")    runners = optional(string, \"runners\")    webhook = optional(string, \"webhook\")  })</pre> <code>{}</code> no state_event_rule_binaries_syncer Option to disable EventBridge Lambda trigger for the binary syncer, useful to stop automatic updates of binary distribution <code>string</code> <code>\"ENABLED\"</code> no subnet_ids List of subnets in which the action runners will be launched, the subnets needs to be subnets in the <code>vpc_id</code>. <code>list(string)</code> n/a yes syncer_lambda_s3_key S3 key for syncer lambda function. Required if using S3 bucket to specify lambdas. <code>string</code> <code>null</code> no syncer_lambda_s3_object_version S3 object version for syncer lambda function. Useful if S3 versioning is enabled on source bucket. <code>string</code> <code>null</code> no tags Map of tags that will be added to created resources. By default resources will be tagged with name and environment. <code>map(string)</code> <code>{}</code> no tracing_config Configuration for lambda tracing. <pre>object({    mode                  = optional(string, null)    capture_http_requests = optional(bool, false)    capture_error         = optional(bool, false)  })</pre> <code>{}</code> no vpc_id The VPC for security groups of the action runners. <code>string</code> n/a yes webhook_lambda_apigateway_access_log_settings Access log settings for webhook API gateway. <pre>object({    destination_arn = string    format          = string  })</pre> <code>null</code> no webhook_lambda_memory_size Memory size limit in MB for webhook lambda. <code>number</code> <code>256</code> no webhook_lambda_s3_key S3 key for webhook lambda function. Required if using S3 bucket to specify lambdas. <code>string</code> <code>null</code> no webhook_lambda_s3_object_version S3 object version for webhook lambda function. Useful if S3 versioning is enabled on source bucket. <code>string</code> <code>null</code> no webhook_lambda_timeout Time out of the lambda in seconds. <code>number</code> <code>10</code> no webhook_lambda_zip File location of the webhook lambda zip file. <code>string</code> <code>null</code> no"},{"location":"modules/public/multi-runner/#outputs","title":"Outputs","text":"Name Description binaries_syncer_map n/a instance_termination_handler n/a instance_termination_watcher n/a runners_map n/a ssm_parameters n/a webhook n/a"},{"location":"modules/public/setup-iam-permissions/","title":"Module - IAM setup for using boundaries","text":"<p>This module is optional and only added as example. You can deploy the root terraform module via you own IAM user with the right credentials. Alternatively you can create a role to deploy the root module with a limit boundary set.</p> <p>This module will create an AWS IAM role that is required to use permission boundaries. The created rol can be used to deploy the root module.</p>"},{"location":"modules/public/setup-iam-permissions/#usages","title":"Usages","text":"<p>See below or check out this example Create a workspace and add the following terraform code.</p> <pre><code>module \"iam\" {\n  source = \"../../\"\n\n  environment = \"default\"\n  account_id  = \"123456789\n\n  namespaces = {\n    boundary_namespace         = \"boundaries\"\n    role_namespace             = \"runners\"\n    policy_namespace           = \"runners\"\n    instance_profile_namespace = \"runners\"\n  }\n}\n\noutput \"role\" {\n  value = module.iam.role\n}\n\noutput \"boundary\" {\n  value = module.iam.boundary\n}\n</code></pre> <p>Next execute the created Terraform code <code>terraform init &amp;&amp; terraform apply</code> The module will. You can use the created role in your terraform provider with assume role and the boundary as well the namespace needs to be set to the root module.</p>"},{"location":"modules/public/setup-iam-permissions/#requirements","title":"Requirements","text":"Name Version terraform &gt;= 1.3.0 aws ~&gt; 5.27"},{"location":"modules/public/setup-iam-permissions/#providers","title":"Providers","text":"Name Version aws ~&gt; 5.27"},{"location":"modules/public/setup-iam-permissions/#modules","title":"Modules","text":"<p>No modules.</p>"},{"location":"modules/public/setup-iam-permissions/#resources","title":"Resources","text":"Name Type aws_iam_policy.boundary resource aws_iam_policy.deploy resource aws_iam_policy.deploy_boundary resource aws_iam_role.deploy resource aws_iam_role_policy_attachment.deploy resource aws_caller_identity.current data source"},{"location":"modules/public/setup-iam-permissions/#inputs","title":"Inputs","text":"Name Description Type Default Required account_id The module allows to switch to the created role from the provided account id. <code>string</code> n/a yes aws_partition (optional) partition in the arn namespace if not aws <code>string</code> <code>\"aws\"</code> no namespaces The role will be only allowed to create roles, policies and instance profiles in the given namespace / path. All policies in the boundaries namespace cannot be modified by this role. <pre>object({    boundary_namespace         = string    role_namespace             = string    policy_namespace           = string    instance_profile_namespace = string  })</pre> n/a yes prefix The prefix used for naming resources <code>string</code> <code>\"github-actions\"</code> no"},{"location":"modules/public/setup-iam-permissions/#outputs","title":"Outputs","text":"Name Description boundary n/a role n/a"}]}